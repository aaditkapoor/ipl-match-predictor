{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We attempt to create a predictor that can predict the outcome of a match given previous wins (2017 IPL Matches).<br>\n",
    "### Using dataset: matches.csv (636 rows)\n",
    "<p>\n",
    "    We create a basic predictor that uses a neural network to predict the match outcome. The model will exported to Django where a web interface will interact with the model.<br>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import Sequential\n",
    "from keras import losses\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss, recall_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "data = pd.read_csv(\"matches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>toss_winner</th>\n",
       "      <th>toss_decision</th>\n",
       "      <th>result</th>\n",
       "      <th>dl_applied</th>\n",
       "      <th>winner</th>\n",
       "      <th>win_by_runs</th>\n",
       "      <th>win_by_wickets</th>\n",
       "      <th>player_of_match</th>\n",
       "      <th>venue</th>\n",
       "      <th>umpire1</th>\n",
       "      <th>umpire2</th>\n",
       "      <th>umpire3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>Sunrisers Hyderabad</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>field</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunrisers Hyderabad</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>Yuvraj Singh</td>\n",
       "      <td>Rajiv Gandhi International Stadium, Uppal</td>\n",
       "      <td>AY Dandekar</td>\n",
       "      <td>NJ Llong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>Mumbai Indians</td>\n",
       "      <td>Rising Pune Supergiant</td>\n",
       "      <td>Rising Pune Supergiant</td>\n",
       "      <td>field</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Rising Pune Supergiant</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>SPD Smith</td>\n",
       "      <td>Maharashtra Cricket Association Stadium</td>\n",
       "      <td>A Nand Kishore</td>\n",
       "      <td>S Ravi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Rajkot</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>Gujarat Lions</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>field</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>CA Lynn</td>\n",
       "      <td>Saurashtra Cricket Association Stadium</td>\n",
       "      <td>Nitin Menon</td>\n",
       "      <td>CK Nandan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>Indore</td>\n",
       "      <td>2017-04-08</td>\n",
       "      <td>Rising Pune Supergiant</td>\n",
       "      <td>Kings XI Punjab</td>\n",
       "      <td>Kings XI Punjab</td>\n",
       "      <td>field</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Kings XI Punjab</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>GJ Maxwell</td>\n",
       "      <td>Holkar Cricket Stadium</td>\n",
       "      <td>AK Chaudhary</td>\n",
       "      <td>C Shamshuddin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>2017-04-08</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>Delhi Daredevils</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>bat</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>KM Jadhav</td>\n",
       "      <td>M Chinnaswamy Stadium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  season       city        date                        team1  \\\n",
       "0   1    2017  Hyderabad  2017-04-05          Sunrisers Hyderabad   \n",
       "1   2    2017       Pune  2017-04-06               Mumbai Indians   \n",
       "2   3    2017     Rajkot  2017-04-07                Gujarat Lions   \n",
       "3   4    2017     Indore  2017-04-08       Rising Pune Supergiant   \n",
       "4   5    2017  Bangalore  2017-04-08  Royal Challengers Bangalore   \n",
       "\n",
       "                         team2                  toss_winner toss_decision  \\\n",
       "0  Royal Challengers Bangalore  Royal Challengers Bangalore         field   \n",
       "1       Rising Pune Supergiant       Rising Pune Supergiant         field   \n",
       "2        Kolkata Knight Riders        Kolkata Knight Riders         field   \n",
       "3              Kings XI Punjab              Kings XI Punjab         field   \n",
       "4             Delhi Daredevils  Royal Challengers Bangalore           bat   \n",
       "\n",
       "   result  dl_applied                       winner  win_by_runs  \\\n",
       "0  normal           0          Sunrisers Hyderabad           35   \n",
       "1  normal           0       Rising Pune Supergiant            0   \n",
       "2  normal           0        Kolkata Knight Riders            0   \n",
       "3  normal           0              Kings XI Punjab            0   \n",
       "4  normal           0  Royal Challengers Bangalore           15   \n",
       "\n",
       "   win_by_wickets player_of_match                                      venue  \\\n",
       "0               0    Yuvraj Singh  Rajiv Gandhi International Stadium, Uppal   \n",
       "1               7       SPD Smith    Maharashtra Cricket Association Stadium   \n",
       "2              10         CA Lynn     Saurashtra Cricket Association Stadium   \n",
       "3               6      GJ Maxwell                     Holkar Cricket Stadium   \n",
       "4               0       KM Jadhav                      M Chinnaswamy Stadium   \n",
       "\n",
       "          umpire1        umpire2  umpire3  \n",
       "0     AY Dandekar       NJ Llong      NaN  \n",
       "1  A Nand Kishore         S Ravi      NaN  \n",
       "2     Nitin Menon      CK Nandan      NaN  \n",
       "3    AK Chaudhary  C Shamshuddin      NaN  \n",
       "4             NaN            NaN      NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unwanted columns\n",
    "data.drop(columns=['venue', 'player_of_match', 'dl_applied','umpire1','umpire2','umpire3','date','city','season','id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding toss_decision\n",
    "data.toss_decision = data.toss_decision.map({'bat':1, 'field':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding result\n",
    "data.result = data.result.map({'normal':1, 'tie':2, 'no result':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = len(data.team2.unique())\n",
    "teams = data.team1.unique()\n",
    "mapping = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(14): # There are 14 teams.\n",
    "    mapping[teams[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.toss_winner = data.toss_winner.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chennai Super Kings': 8,\n",
       " 'Deccan Chargers': 10,\n",
       " 'Delhi Daredevils': 6,\n",
       " 'Gujarat Lions': 2,\n",
       " 'Kings XI Punjab': 7,\n",
       " 'Kochi Tuskers Kerala': 11,\n",
       " 'Kolkata Knight Riders': 5,\n",
       " 'Mumbai Indians': 1,\n",
       " 'Pune Warriors': 12,\n",
       " 'Rajasthan Royals': 9,\n",
       " 'Rising Pune Supergiant': 3,\n",
       " 'Rising Pune Supergiants': 13,\n",
       " 'Royal Challengers Bangalore': 4,\n",
       " 'Sunrisers Hyderabad': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding team data in numeric form\n",
    "data.team1 = data.team1.map(mapping)\n",
    "data.team2 = data.team2.map(mapping)\n",
    "mapping # A value is repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.winner = data.winner.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NA Fields\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.winner = data.winner.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>toss_winner</th>\n",
       "      <th>toss_decision</th>\n",
       "      <th>result</th>\n",
       "      <th>winner</th>\n",
       "      <th>win_by_runs</th>\n",
       "      <th>win_by_wickets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team1  team2  toss_winner  toss_decision  result  winner  win_by_runs  \\\n",
       "0      0      4            4              0       1       0           35   \n",
       "1      1      3            3              0       1       3            0   \n",
       "2      2      5            5              0       1       5            0   \n",
       "3      3      7            7              0       1       7            0   \n",
       "4      4      6            4              1       1       4           15   \n",
       "\n",
       "   win_by_wickets  \n",
       "0               0  \n",
       "1               7  \n",
       "2              10  \n",
       "3               6  \n",
       "4               0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "633"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    While we think that <b>win_by_runs</b> and <b> win_by_wickets </b> are important metrics for the dataset, we are dropping it for user's simplicity.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"win_by_runs\", \"win_by_wickets\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>toss_winner</th>\n",
       "      <th>toss_decision</th>\n",
       "      <th>result</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team1  team2  toss_winner  toss_decision  result  winner\n",
       "0      0      4            4              0       1       0\n",
       "1      1      3            3              0       1       3\n",
       "2      2      5            5              0       1       5\n",
       "3      3      7            7              0       1       7\n",
       "4      4      6            4              1       1       4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"toss_decision\", \"result\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>toss_winner</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team1  team2  toss_winner  winner\n",
       "0      0      4            4       0\n",
       "1      1      3            3       3\n",
       "2      2      5            5       5\n",
       "3      3      7            7       7\n",
       "4      4      6            4       4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.winner.values\n",
    "features = data.drop(columns=[\"winner\"], axis=1).values\n",
    "\n",
    "labels_copy = data.winner.values\n",
    "features_copy = data.drop(columns=[\"winner\"], axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(633, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(633,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have three input dim\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As there is no activaton function that can predict 'winner', we are one hot encoding it.\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(633, 14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will use a softmax which will provide probs for 14 different classes aka teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train,labels_test = train_test_split(features, labels, shuffle=True, random_state=42)\n",
    "features_copy_train, features_copy_test, labels_copy_train,labels_copy_test = train_test_split(features, labels, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation=\"relu\", input_dim=features.shape[1]))\n",
    "model.add(Dense(75, activation=\"relu\"))\n",
    "model.add(Dense(75, activation=\"relu\"))\n",
    "model.add(Dense(labels.shape[1], activation=\"softmax\"))\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss=losses.categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 75)                5700      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 14)                1064      \n",
      "=================================================================\n",
      "Total params: 14,739\n",
      "Trainable params: 14,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 474 samples, validate on 159 samples\n",
      "Epoch 1/1000\n",
      "474/474 [==============================] - 0s 828us/step - loss: 2.5497 - acc: 0.1181 - val_loss: 2.3543 - val_acc: 0.2013\n",
      "Epoch 2/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 2.3696 - acc: 0.2004 - val_loss: 2.2587 - val_acc: 0.2013\n",
      "Epoch 3/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 2.2838 - acc: 0.2321 - val_loss: 2.1899 - val_acc: 0.2642\n",
      "Epoch 4/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 2.2168 - acc: 0.2426 - val_loss: 2.1594 - val_acc: 0.2642\n",
      "Epoch 5/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 2.1714 - acc: 0.2363 - val_loss: 2.1430 - val_acc: 0.2956\n",
      "Epoch 6/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 2.1319 - acc: 0.2827 - val_loss: 2.1234 - val_acc: 0.3019\n",
      "Epoch 7/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 2.0975 - acc: 0.2975 - val_loss: 2.1402 - val_acc: 0.3145\n",
      "Epoch 8/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 2.0722 - acc: 0.2722 - val_loss: 2.1230 - val_acc: 0.3396\n",
      "Epoch 9/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 2.0374 - acc: 0.3207 - val_loss: 2.1154 - val_acc: 0.3396\n",
      "Epoch 10/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 2.0162 - acc: 0.3228 - val_loss: 2.1205 - val_acc: 0.3585\n",
      "Epoch 11/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 1.9925 - acc: 0.3418 - val_loss: 2.1123 - val_acc: 0.3585\n",
      "Epoch 12/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 1.9684 - acc: 0.3228 - val_loss: 2.1110 - val_acc: 0.3648\n",
      "Epoch 13/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 1.9592 - acc: 0.3397 - val_loss: 2.1105 - val_acc: 0.3648\n",
      "Epoch 14/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 1.9460 - acc: 0.3270 - val_loss: 2.1090 - val_acc: 0.3270\n",
      "Epoch 15/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 1.9159 - acc: 0.3608 - val_loss: 2.1361 - val_acc: 0.3585\n",
      "Epoch 16/1000\n",
      "474/474 [==============================] - 0s 138us/step - loss: 1.8966 - acc: 0.3671 - val_loss: 2.1236 - val_acc: 0.3522\n",
      "Epoch 17/1000\n",
      "474/474 [==============================] - 0s 140us/step - loss: 1.8785 - acc: 0.3671 - val_loss: 2.1237 - val_acc: 0.3899\n",
      "Epoch 18/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 1.8737 - acc: 0.3713 - val_loss: 2.1088 - val_acc: 0.3208\n",
      "Epoch 19/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 1.8602 - acc: 0.3713 - val_loss: 2.1065 - val_acc: 0.3899\n",
      "Epoch 20/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 1.8466 - acc: 0.3439 - val_loss: 2.1079 - val_acc: 0.3711\n",
      "Epoch 21/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 1.8267 - acc: 0.3840 - val_loss: 2.1174 - val_acc: 0.3711\n",
      "Epoch 22/1000\n",
      "474/474 [==============================] - 0s 146us/step - loss: 1.8314 - acc: 0.3713 - val_loss: 2.0894 - val_acc: 0.3522\n",
      "Epoch 23/1000\n",
      "474/474 [==============================] - 0s 146us/step - loss: 1.8156 - acc: 0.3776 - val_loss: 2.1064 - val_acc: 0.3899\n",
      "Epoch 24/1000\n",
      "474/474 [==============================] - 0s 145us/step - loss: 1.7923 - acc: 0.3924 - val_loss: 2.0510 - val_acc: 0.3962\n",
      "Epoch 25/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 1.7655 - acc: 0.4135 - val_loss: 2.0790 - val_acc: 0.3459\n",
      "Epoch 26/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 1.7588 - acc: 0.3713 - val_loss: 2.0553 - val_acc: 0.3459\n",
      "Epoch 27/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 1.7286 - acc: 0.4135 - val_loss: 2.0587 - val_acc: 0.3774\n",
      "Epoch 28/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 1.7309 - acc: 0.4030 - val_loss: 2.0768 - val_acc: 0.3774\n",
      "Epoch 29/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 1.7196 - acc: 0.4051 - val_loss: 2.0508 - val_acc: 0.3208\n",
      "Epoch 30/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 1.7136 - acc: 0.3882 - val_loss: 2.0947 - val_acc: 0.3899\n",
      "Epoch 31/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 1.7067 - acc: 0.3966 - val_loss: 2.0339 - val_acc: 0.3774\n",
      "Epoch 32/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 1.6853 - acc: 0.4114 - val_loss: 2.0288 - val_acc: 0.3774\n",
      "Epoch 33/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 1.6697 - acc: 0.4093 - val_loss: 2.0444 - val_acc: 0.3899\n",
      "Epoch 34/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 1.6589 - acc: 0.4177 - val_loss: 2.0384 - val_acc: 0.3899\n",
      "Epoch 35/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 1.6522 - acc: 0.4283 - val_loss: 2.0306 - val_acc: 0.3711\n",
      "Epoch 36/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 1.6324 - acc: 0.4262 - val_loss: 1.9930 - val_acc: 0.3962\n",
      "Epoch 37/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 1.6171 - acc: 0.4114 - val_loss: 2.0422 - val_acc: 0.3711\n",
      "Epoch 38/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 1.6344 - acc: 0.4135 - val_loss: 1.9926 - val_acc: 0.3836\n",
      "Epoch 39/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 1.5882 - acc: 0.4325 - val_loss: 2.0217 - val_acc: 0.4025\n",
      "Epoch 40/1000\n",
      "474/474 [==============================] - 0s 136us/step - loss: 1.5899 - acc: 0.4346 - val_loss: 1.9942 - val_acc: 0.3836\n",
      "Epoch 41/1000\n",
      "474/474 [==============================] - 0s 141us/step - loss: 1.5701 - acc: 0.4198 - val_loss: 1.9777 - val_acc: 0.3962\n",
      "Epoch 42/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 1.5765 - acc: 0.4219 - val_loss: 2.0008 - val_acc: 0.4151\n",
      "Epoch 43/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 1.5711 - acc: 0.4093 - val_loss: 1.9792 - val_acc: 0.4151\n",
      "Epoch 44/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 1.5551 - acc: 0.4156 - val_loss: 1.9909 - val_acc: 0.3899\n",
      "Epoch 45/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 1.5447 - acc: 0.4177 - val_loss: 2.0106 - val_acc: 0.3962\n",
      "Epoch 46/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 1.5360 - acc: 0.4346 - val_loss: 2.0292 - val_acc: 0.4088\n",
      "Epoch 47/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 1.5349 - acc: 0.4093 - val_loss: 2.0167 - val_acc: 0.4151\n",
      "Epoch 48/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 1.5406 - acc: 0.4177 - val_loss: 1.9709 - val_acc: 0.3774\n",
      "Epoch 49/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 1.5178 - acc: 0.4262 - val_loss: 1.9956 - val_acc: 0.4340\n",
      "Epoch 50/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 1.5146 - acc: 0.4156 - val_loss: 1.9662 - val_acc: 0.3962\n",
      "Epoch 51/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 1.5032 - acc: 0.4241 - val_loss: 2.0021 - val_acc: 0.3459\n",
      "Epoch 52/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 1.4900 - acc: 0.4473 - val_loss: 2.0418 - val_acc: 0.3711\n",
      "Epoch 53/1000\n",
      "474/474 [==============================] - 0s 139us/step - loss: 1.4898 - acc: 0.4346 - val_loss: 1.9838 - val_acc: 0.3962\n",
      "Epoch 54/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 1.4739 - acc: 0.4515 - val_loss: 1.9690 - val_acc: 0.4151\n",
      "Epoch 55/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 1.4828 - acc: 0.4494 - val_loss: 2.0054 - val_acc: 0.3648\n",
      "Epoch 56/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 1.4575 - acc: 0.4304 - val_loss: 1.9552 - val_acc: 0.4214\n",
      "Epoch 57/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 1.4268 - acc: 0.4641 - val_loss: 1.9699 - val_acc: 0.4340\n",
      "Epoch 58/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 1.4463 - acc: 0.4325 - val_loss: 2.0164 - val_acc: 0.3774\n",
      "Epoch 59/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 1.4493 - acc: 0.4114 - val_loss: 2.0033 - val_acc: 0.4088\n",
      "Epoch 60/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 1.4578 - acc: 0.4557 - val_loss: 2.0084 - val_acc: 0.3962\n",
      "Epoch 61/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 1.4367 - acc: 0.4409 - val_loss: 2.0010 - val_acc: 0.4340\n",
      "Epoch 62/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 1.4254 - acc: 0.4494 - val_loss: 1.9916 - val_acc: 0.4088\n",
      "Epoch 63/1000\n",
      "474/474 [==============================] - 0s 144us/step - loss: 1.4381 - acc: 0.4557 - val_loss: 1.9646 - val_acc: 0.4025\n",
      "Epoch 64/1000\n",
      "474/474 [==============================] - 0s 175us/step - loss: 1.4109 - acc: 0.4641 - val_loss: 2.0358 - val_acc: 0.4277\n",
      "Epoch 65/1000\n",
      "474/474 [==============================] - 0s 163us/step - loss: 1.4038 - acc: 0.4705 - val_loss: 1.9593 - val_acc: 0.4591\n",
      "Epoch 66/1000\n",
      "474/474 [==============================] - 0s 144us/step - loss: 1.4052 - acc: 0.4536 - val_loss: 1.9990 - val_acc: 0.3836\n",
      "Epoch 67/1000\n",
      "474/474 [==============================] - 0s 142us/step - loss: 1.3901 - acc: 0.4641 - val_loss: 1.9850 - val_acc: 0.4654\n",
      "Epoch 68/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 1.3977 - acc: 0.4726 - val_loss: 2.0141 - val_acc: 0.4025\n",
      "Epoch 69/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 1.3784 - acc: 0.4684 - val_loss: 2.0017 - val_acc: 0.4780\n",
      "Epoch 70/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 1.3851 - acc: 0.4536 - val_loss: 2.0045 - val_acc: 0.4654\n",
      "Epoch 71/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 1.3863 - acc: 0.4916 - val_loss: 2.0052 - val_acc: 0.4151\n",
      "Epoch 72/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 1.3948 - acc: 0.4599 - val_loss: 1.9961 - val_acc: 0.3648\n",
      "Epoch 73/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 1.3677 - acc: 0.4705 - val_loss: 2.0053 - val_acc: 0.4340\n",
      "Epoch 74/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 1.3558 - acc: 0.4768 - val_loss: 1.9943 - val_acc: 0.4780\n",
      "Epoch 75/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 1.3413 - acc: 0.4852 - val_loss: 1.9748 - val_acc: 0.4403\n",
      "Epoch 76/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 1.3534 - acc: 0.4684 - val_loss: 1.9806 - val_acc: 0.4151\n",
      "Epoch 77/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 1.3344 - acc: 0.4599 - val_loss: 1.9942 - val_acc: 0.4843\n",
      "Epoch 78/1000\n",
      "474/474 [==============================] - 0s 180us/step - loss: 1.3322 - acc: 0.5021 - val_loss: 1.9749 - val_acc: 0.3774\n",
      "Epoch 79/1000\n",
      "474/474 [==============================] - 0s 174us/step - loss: 1.3355 - acc: 0.4895 - val_loss: 1.9802 - val_acc: 0.4717\n",
      "Epoch 80/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 1.3482 - acc: 0.4789 - val_loss: 2.0249 - val_acc: 0.4465\n",
      "Epoch 81/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 1.3295 - acc: 0.4852 - val_loss: 1.9537 - val_acc: 0.3962\n",
      "Epoch 82/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 1.3280 - acc: 0.4916 - val_loss: 1.9969 - val_acc: 0.4403\n",
      "Epoch 83/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 1.3212 - acc: 0.4662 - val_loss: 2.0127 - val_acc: 0.4654\n",
      "Epoch 84/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 1.3230 - acc: 0.4831 - val_loss: 2.0574 - val_acc: 0.4528\n",
      "Epoch 85/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 1.3486 - acc: 0.4768 - val_loss: 2.0103 - val_acc: 0.4717\n",
      "Epoch 86/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 1.3182 - acc: 0.4557 - val_loss: 1.9938 - val_acc: 0.4843\n",
      "Epoch 87/1000\n",
      "474/474 [==============================] - 0s 136us/step - loss: 1.3029 - acc: 0.4768 - val_loss: 2.0170 - val_acc: 0.3962\n",
      "Epoch 88/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 1.2940 - acc: 0.4705 - val_loss: 2.0222 - val_acc: 0.4654\n",
      "Epoch 89/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 1.3128 - acc: 0.4895 - val_loss: 2.0179 - val_acc: 0.4780\n",
      "Epoch 90/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 1.2941 - acc: 0.4873 - val_loss: 2.0498 - val_acc: 0.4025\n",
      "Epoch 91/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 1.2898 - acc: 0.4979 - val_loss: 1.9656 - val_acc: 0.4654\n",
      "Epoch 92/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 1.2683 - acc: 0.5021 - val_loss: 2.1014 - val_acc: 0.3711\n",
      "Epoch 93/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 1.2791 - acc: 0.4578 - val_loss: 1.9860 - val_acc: 0.4088\n",
      "Epoch 94/1000\n",
      "474/474 [==============================] - 0s 143us/step - loss: 1.2748 - acc: 0.5021 - val_loss: 2.0236 - val_acc: 0.4843\n",
      "Epoch 95/1000\n",
      "474/474 [==============================] - 0s 135us/step - loss: 1.2706 - acc: 0.4831 - val_loss: 1.9872 - val_acc: 0.4465\n",
      "Epoch 96/1000\n",
      "474/474 [==============================] - 0s 151us/step - loss: 1.2767 - acc: 0.5021 - val_loss: 2.1398 - val_acc: 0.4214\n",
      "Epoch 97/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 1.2859 - acc: 0.4916 - val_loss: 2.0168 - val_acc: 0.4528\n",
      "Epoch 98/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 1.2560 - acc: 0.4958 - val_loss: 1.9937 - val_acc: 0.3774\n",
      "Epoch 99/1000\n",
      "474/474 [==============================] - 0s 165us/step - loss: 1.2603 - acc: 0.5000 - val_loss: 2.0149 - val_acc: 0.4906\n",
      "Epoch 100/1000\n",
      "474/474 [==============================] - 0s 139us/step - loss: 1.2523 - acc: 0.5274 - val_loss: 2.0490 - val_acc: 0.3962\n",
      "Epoch 101/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 1.2401 - acc: 0.5042 - val_loss: 1.9757 - val_acc: 0.4340\n",
      "Epoch 102/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 1.2419 - acc: 0.5127 - val_loss: 2.0040 - val_acc: 0.4025\n",
      "Epoch 103/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 1.2457 - acc: 0.5084 - val_loss: 2.0710 - val_acc: 0.4780\n",
      "Epoch 104/1000\n",
      "474/474 [==============================] - 0s 143us/step - loss: 1.2387 - acc: 0.4705 - val_loss: 2.0319 - val_acc: 0.4906\n",
      "Epoch 105/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 1.2187 - acc: 0.5105 - val_loss: 2.0288 - val_acc: 0.4969\n",
      "Epoch 106/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 1.2224 - acc: 0.5169 - val_loss: 2.0690 - val_acc: 0.3774\n",
      "Epoch 107/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 1.2565 - acc: 0.5042 - val_loss: 2.0266 - val_acc: 0.4906\n",
      "Epoch 108/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 1.2403 - acc: 0.4852 - val_loss: 2.0056 - val_acc: 0.4591\n",
      "Epoch 109/1000\n",
      "474/474 [==============================] - 0s 151us/step - loss: 1.2094 - acc: 0.5190 - val_loss: 2.0069 - val_acc: 0.4340\n",
      "Epoch 110/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 1.2074 - acc: 0.5148 - val_loss: 2.0592 - val_acc: 0.4843\n",
      "Epoch 111/1000\n",
      "474/474 [==============================] - 0s 134us/step - loss: 1.2093 - acc: 0.4979 - val_loss: 2.0592 - val_acc: 0.4340\n",
      "Epoch 112/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 1.2234 - acc: 0.4916 - val_loss: 1.9764 - val_acc: 0.4465\n",
      "Epoch 113/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 1.2173 - acc: 0.4979 - val_loss: 2.0825 - val_acc: 0.4654\n",
      "Epoch 114/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 1.2094 - acc: 0.5274 - val_loss: 2.0206 - val_acc: 0.4780\n",
      "Epoch 115/1000\n",
      "474/474 [==============================] - 0s 140us/step - loss: 1.2028 - acc: 0.5000 - val_loss: 2.0649 - val_acc: 0.4151\n",
      "Epoch 116/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 1.1970 - acc: 0.4958 - val_loss: 2.0064 - val_acc: 0.4591\n",
      "Epoch 117/1000\n",
      "474/474 [==============================] - 0s 133us/step - loss: 1.1997 - acc: 0.5105 - val_loss: 2.0093 - val_acc: 0.4340\n",
      "Epoch 118/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 1.1757 - acc: 0.5105 - val_loss: 1.9994 - val_acc: 0.4906\n",
      "Epoch 119/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 1.1721 - acc: 0.5232 - val_loss: 2.0246 - val_acc: 0.4780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "474/474 [==============================] - 0s 149us/step - loss: 1.1847 - acc: 0.5190 - val_loss: 2.0346 - val_acc: 0.4340\n",
      "Epoch 121/1000\n",
      "474/474 [==============================] - 0s 153us/step - loss: 1.1959 - acc: 0.4979 - val_loss: 2.0143 - val_acc: 0.5157\n",
      "Epoch 122/1000\n",
      "474/474 [==============================] - 0s 146us/step - loss: 1.1922 - acc: 0.5105 - val_loss: 1.9817 - val_acc: 0.4906\n",
      "Epoch 123/1000\n",
      "474/474 [==============================] - 0s 152us/step - loss: 1.1412 - acc: 0.5506 - val_loss: 2.0556 - val_acc: 0.4591\n",
      "Epoch 124/1000\n",
      "474/474 [==============================] - 0s 148us/step - loss: 1.1610 - acc: 0.5338 - val_loss: 2.0249 - val_acc: 0.4969\n",
      "Epoch 125/1000\n",
      "474/474 [==============================] - 0s 140us/step - loss: 1.1610 - acc: 0.5042 - val_loss: 2.0417 - val_acc: 0.5031\n",
      "Epoch 126/1000\n",
      "474/474 [==============================] - 0s 137us/step - loss: 1.1516 - acc: 0.5232 - val_loss: 2.0439 - val_acc: 0.4277\n",
      "Epoch 127/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 1.1415 - acc: 0.5380 - val_loss: 2.0416 - val_acc: 0.4717\n",
      "Epoch 128/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 1.1369 - acc: 0.5422 - val_loss: 2.0117 - val_acc: 0.4843\n",
      "Epoch 129/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 1.1529 - acc: 0.5253 - val_loss: 2.0555 - val_acc: 0.4528\n",
      "Epoch 130/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 1.1461 - acc: 0.5232 - val_loss: 2.0544 - val_acc: 0.5031\n",
      "Epoch 131/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 1.1474 - acc: 0.5401 - val_loss: 2.0031 - val_acc: 0.4277\n",
      "Epoch 132/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 1.1517 - acc: 0.5422 - val_loss: 2.0413 - val_acc: 0.4025\n",
      "Epoch 133/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 1.1416 - acc: 0.5422 - val_loss: 2.0582 - val_acc: 0.4465\n",
      "Epoch 134/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 1.1298 - acc: 0.5485 - val_loss: 2.0278 - val_acc: 0.4780\n",
      "Epoch 135/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 1.1304 - acc: 0.5401 - val_loss: 2.0523 - val_acc: 0.4528\n",
      "Epoch 136/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 1.1159 - acc: 0.5549 - val_loss: 2.0182 - val_acc: 0.4843\n",
      "Epoch 137/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 1.1417 - acc: 0.5464 - val_loss: 2.0857 - val_acc: 0.4403\n",
      "Epoch 138/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 1.1165 - acc: 0.5464 - val_loss: 2.0616 - val_acc: 0.3899\n",
      "Epoch 139/1000\n",
      "474/474 [==============================] - 0s 135us/step - loss: 1.1549 - acc: 0.5127 - val_loss: 2.0268 - val_acc: 0.4340\n",
      "Epoch 140/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 1.1116 - acc: 0.5612 - val_loss: 2.0027 - val_acc: 0.4528\n",
      "Epoch 141/1000\n",
      "474/474 [==============================] - 0s 135us/step - loss: 1.1023 - acc: 0.5295 - val_loss: 2.0369 - val_acc: 0.4465\n",
      "Epoch 142/1000\n",
      "474/474 [==============================] - 0s 154us/step - loss: 1.1099 - acc: 0.5781 - val_loss: 2.0455 - val_acc: 0.4717\n",
      "Epoch 143/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 1.0941 - acc: 0.5570 - val_loss: 2.0268 - val_acc: 0.5220\n",
      "Epoch 144/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 1.0941 - acc: 0.5443 - val_loss: 2.0345 - val_acc: 0.4906\n",
      "Epoch 145/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 1.1031 - acc: 0.5591 - val_loss: 2.0349 - val_acc: 0.5031\n",
      "Epoch 146/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 1.0977 - acc: 0.5401 - val_loss: 2.0233 - val_acc: 0.4717\n",
      "Epoch 147/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 1.1120 - acc: 0.5380 - val_loss: 2.0860 - val_acc: 0.5031\n",
      "Epoch 148/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 1.1083 - acc: 0.5274 - val_loss: 2.0389 - val_acc: 0.4969\n",
      "Epoch 149/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 1.0811 - acc: 0.5696 - val_loss: 2.0939 - val_acc: 0.4340\n",
      "Epoch 150/1000\n",
      "474/474 [==============================] - 0s 139us/step - loss: 1.0999 - acc: 0.5549 - val_loss: 2.0303 - val_acc: 0.4780\n",
      "Epoch 151/1000\n",
      "474/474 [==============================] - 0s 146us/step - loss: 1.0923 - acc: 0.5654 - val_loss: 2.1260 - val_acc: 0.4528\n",
      "Epoch 152/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 1.0880 - acc: 0.5591 - val_loss: 2.0032 - val_acc: 0.5220\n",
      "Epoch 153/1000\n",
      "474/474 [==============================] - 0s 136us/step - loss: 1.0811 - acc: 0.5781 - val_loss: 2.0818 - val_acc: 0.4969\n",
      "Epoch 154/1000\n",
      "474/474 [==============================] - 0s 136us/step - loss: 1.0871 - acc: 0.5401 - val_loss: 2.0238 - val_acc: 0.4591\n",
      "Epoch 155/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 1.0714 - acc: 0.5717 - val_loss: 2.0258 - val_acc: 0.4717\n",
      "Epoch 156/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 1.0637 - acc: 0.5570 - val_loss: 2.0623 - val_acc: 0.4403\n",
      "Epoch 157/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 1.0585 - acc: 0.5527 - val_loss: 2.0149 - val_acc: 0.4969\n",
      "Epoch 158/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 1.0457 - acc: 0.5549 - val_loss: 2.0679 - val_acc: 0.4843\n",
      "Epoch 159/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 1.0584 - acc: 0.5485 - val_loss: 1.9943 - val_acc: 0.4843\n",
      "Epoch 160/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 1.0446 - acc: 0.5717 - val_loss: 2.0537 - val_acc: 0.5157\n",
      "Epoch 161/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 1.0634 - acc: 0.5759 - val_loss: 2.0471 - val_acc: 0.5283\n",
      "Epoch 162/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 1.0590 - acc: 0.5380 - val_loss: 2.0187 - val_acc: 0.4717\n",
      "Epoch 163/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 1.0438 - acc: 0.5781 - val_loss: 2.0109 - val_acc: 0.4717\n",
      "Epoch 164/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 1.0275 - acc: 0.6034 - val_loss: 2.0795 - val_acc: 0.4969\n",
      "Epoch 165/1000\n",
      "474/474 [==============================] - 0s 141us/step - loss: 1.0452 - acc: 0.5591 - val_loss: 2.0068 - val_acc: 0.5157\n",
      "Epoch 166/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 1.0683 - acc: 0.5485 - val_loss: 2.0328 - val_acc: 0.4340\n",
      "Epoch 167/1000\n",
      "474/474 [==============================] - 0s 136us/step - loss: 1.0241 - acc: 0.5633 - val_loss: 2.0313 - val_acc: 0.5031\n",
      "Epoch 168/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 1.0456 - acc: 0.5654 - val_loss: 2.0437 - val_acc: 0.5157\n",
      "Epoch 169/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 1.0213 - acc: 0.5675 - val_loss: 2.0060 - val_acc: 0.5031\n",
      "Epoch 170/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 1.0378 - acc: 0.5570 - val_loss: 1.9999 - val_acc: 0.5157\n",
      "Epoch 171/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 1.0350 - acc: 0.5464 - val_loss: 2.0031 - val_acc: 0.5094\n",
      "Epoch 172/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 1.0205 - acc: 0.5570 - val_loss: 1.9948 - val_acc: 0.4969\n",
      "Epoch 173/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 1.0431 - acc: 0.5633 - val_loss: 1.9988 - val_acc: 0.4465\n",
      "Epoch 174/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 1.0269 - acc: 0.5675 - val_loss: 2.0377 - val_acc: 0.4969\n",
      "Epoch 175/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 1.0157 - acc: 0.5759 - val_loss: 1.9514 - val_acc: 0.4969\n",
      "Epoch 176/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 1.0041 - acc: 0.5928 - val_loss: 2.0187 - val_acc: 0.5094\n",
      "Epoch 177/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.9994 - acc: 0.5823 - val_loss: 1.9951 - val_acc: 0.5157\n",
      "Epoch 178/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 1.0259 - acc: 0.6034 - val_loss: 2.0330 - val_acc: 0.4780\n",
      "Epoch 179/1000\n",
      "474/474 [==============================] - 0s 133us/step - loss: 1.0177 - acc: 0.5928 - val_loss: 1.9820 - val_acc: 0.5094\n",
      "Epoch 180/1000\n",
      "474/474 [==============================] - 0s 144us/step - loss: 0.9681 - acc: 0.5823 - val_loss: 2.0060 - val_acc: 0.4403\n",
      "Epoch 181/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 1.0055 - acc: 0.5591 - val_loss: 1.9856 - val_acc: 0.4969\n",
      "Epoch 182/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.9952 - acc: 0.5738 - val_loss: 1.9985 - val_acc: 0.5283\n",
      "Epoch 183/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 1.0118 - acc: 0.5443 - val_loss: 1.9569 - val_acc: 0.5157\n",
      "Epoch 184/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.9939 - acc: 0.5823 - val_loss: 2.0174 - val_acc: 0.4717\n",
      "Epoch 185/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.9786 - acc: 0.5949 - val_loss: 1.9574 - val_acc: 0.5220\n",
      "Epoch 186/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.9811 - acc: 0.5907 - val_loss: 1.9976 - val_acc: 0.5031\n",
      "Epoch 187/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.9680 - acc: 0.5738 - val_loss: 1.9584 - val_acc: 0.4906\n",
      "Epoch 188/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.9884 - acc: 0.5464 - val_loss: 1.9086 - val_acc: 0.5535\n",
      "Epoch 189/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.9822 - acc: 0.5612 - val_loss: 1.9473 - val_acc: 0.5031\n",
      "Epoch 190/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.9687 - acc: 0.5654 - val_loss: 1.9731 - val_acc: 0.5031\n",
      "Epoch 191/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.9714 - acc: 0.5802 - val_loss: 1.9507 - val_acc: 0.5157\n",
      "Epoch 192/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.9649 - acc: 0.5781 - val_loss: 1.9865 - val_acc: 0.4717\n",
      "Epoch 193/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 0.9753 - acc: 0.5802 - val_loss: 2.0274 - val_acc: 0.4591\n",
      "Epoch 194/1000\n",
      "474/474 [==============================] - 0s 163us/step - loss: 0.9728 - acc: 0.5949 - val_loss: 1.9274 - val_acc: 0.5157\n",
      "Epoch 195/1000\n",
      "474/474 [==============================] - 0s 135us/step - loss: 0.9785 - acc: 0.5781 - val_loss: 2.0991 - val_acc: 0.5283\n",
      "Epoch 196/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.9782 - acc: 0.5675 - val_loss: 1.9361 - val_acc: 0.5094\n",
      "Epoch 197/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.9679 - acc: 0.5886 - val_loss: 1.9704 - val_acc: 0.5094\n",
      "Epoch 198/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.9422 - acc: 0.6013 - val_loss: 1.9211 - val_acc: 0.4843\n",
      "Epoch 199/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.9412 - acc: 0.5781 - val_loss: 1.9403 - val_acc: 0.5283\n",
      "Epoch 200/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.9317 - acc: 0.5823 - val_loss: 2.0000 - val_acc: 0.4969\n",
      "Epoch 201/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.9425 - acc: 0.5781 - val_loss: 1.8942 - val_acc: 0.5723\n",
      "Epoch 202/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.9434 - acc: 0.5844 - val_loss: 1.9424 - val_acc: 0.5157\n",
      "Epoch 203/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.9313 - acc: 0.6139 - val_loss: 1.9732 - val_acc: 0.5346\n",
      "Epoch 204/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.9322 - acc: 0.5759 - val_loss: 1.9595 - val_acc: 0.4969\n",
      "Epoch 205/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.9326 - acc: 0.5970 - val_loss: 1.9448 - val_acc: 0.5409\n",
      "Epoch 206/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.9240 - acc: 0.5802 - val_loss: 2.0001 - val_acc: 0.4969\n",
      "Epoch 207/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.9495 - acc: 0.5907 - val_loss: 1.9542 - val_acc: 0.4843\n",
      "Epoch 208/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.9104 - acc: 0.6160 - val_loss: 1.9601 - val_acc: 0.5346\n",
      "Epoch 209/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.9504 - acc: 0.5823 - val_loss: 1.9524 - val_acc: 0.5094\n",
      "Epoch 210/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.9586 - acc: 0.5907 - val_loss: 1.9666 - val_acc: 0.4906\n",
      "Epoch 211/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.9514 - acc: 0.5907 - val_loss: 1.8955 - val_acc: 0.5535\n",
      "Epoch 212/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.9283 - acc: 0.5970 - val_loss: 1.9561 - val_acc: 0.5472\n",
      "Epoch 213/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.9268 - acc: 0.6160 - val_loss: 2.0177 - val_acc: 0.4906\n",
      "Epoch 214/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.9243 - acc: 0.5928 - val_loss: 1.9106 - val_acc: 0.4969\n",
      "Epoch 215/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.9613 - acc: 0.5865 - val_loss: 1.9451 - val_acc: 0.4528\n",
      "Epoch 216/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.9353 - acc: 0.5759 - val_loss: 1.9166 - val_acc: 0.5346\n",
      "Epoch 217/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.9027 - acc: 0.6139 - val_loss: 1.9519 - val_acc: 0.5346\n",
      "Epoch 218/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.9166 - acc: 0.5696 - val_loss: 1.9349 - val_acc: 0.5157\n",
      "Epoch 219/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.9087 - acc: 0.6118 - val_loss: 1.9060 - val_acc: 0.5346\n",
      "Epoch 220/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.9312 - acc: 0.5844 - val_loss: 1.9433 - val_acc: 0.4906\n",
      "Epoch 221/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.9306 - acc: 0.5823 - val_loss: 1.9174 - val_acc: 0.5094\n",
      "Epoch 222/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.9099 - acc: 0.6097 - val_loss: 1.9141 - val_acc: 0.5220\n",
      "Epoch 223/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.9131 - acc: 0.5802 - val_loss: 1.9323 - val_acc: 0.5346\n",
      "Epoch 224/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.8925 - acc: 0.5759 - val_loss: 1.8991 - val_acc: 0.5409\n",
      "Epoch 225/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.9179 - acc: 0.6076 - val_loss: 1.9178 - val_acc: 0.4654\n",
      "Epoch 226/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.9018 - acc: 0.6139 - val_loss: 1.9444 - val_acc: 0.5031\n",
      "Epoch 227/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.8842 - acc: 0.6139 - val_loss: 1.9374 - val_acc: 0.5283\n",
      "Epoch 228/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.8999 - acc: 0.6013 - val_loss: 1.9282 - val_acc: 0.4969\n",
      "Epoch 229/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.8836 - acc: 0.6013 - val_loss: 1.9244 - val_acc: 0.5283\n",
      "Epoch 230/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8725 - acc: 0.6203 - val_loss: 1.9226 - val_acc: 0.5283\n",
      "Epoch 231/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.9013 - acc: 0.6097 - val_loss: 1.9278 - val_acc: 0.5220\n",
      "Epoch 232/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.9091 - acc: 0.5970 - val_loss: 1.9033 - val_acc: 0.5346\n",
      "Epoch 233/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.8870 - acc: 0.5844 - val_loss: 1.9433 - val_acc: 0.4654\n",
      "Epoch 234/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.8930 - acc: 0.6139 - val_loss: 1.9286 - val_acc: 0.5157\n",
      "Epoch 235/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.8890 - acc: 0.6013 - val_loss: 1.9372 - val_acc: 0.5094\n",
      "Epoch 236/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.8826 - acc: 0.6181 - val_loss: 1.9252 - val_acc: 0.5157\n",
      "Epoch 237/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.8973 - acc: 0.5992 - val_loss: 1.9074 - val_acc: 0.5597\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/474 [==============================] - 0s 115us/step - loss: 0.8872 - acc: 0.5949 - val_loss: 1.9037 - val_acc: 0.5472\n",
      "Epoch 239/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.8970 - acc: 0.5928 - val_loss: 1.9397 - val_acc: 0.5094\n",
      "Epoch 240/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8844 - acc: 0.6224 - val_loss: 1.9230 - val_acc: 0.4969\n",
      "Epoch 241/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.9044 - acc: 0.6034 - val_loss: 1.8915 - val_acc: 0.5094\n",
      "Epoch 242/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.8889 - acc: 0.6203 - val_loss: 1.9896 - val_acc: 0.5157\n",
      "Epoch 243/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.8797 - acc: 0.6013 - val_loss: 1.9756 - val_acc: 0.5220\n",
      "Epoch 244/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.8736 - acc: 0.5802 - val_loss: 1.9147 - val_acc: 0.5220\n",
      "Epoch 245/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.8695 - acc: 0.6266 - val_loss: 1.9611 - val_acc: 0.5283\n",
      "Epoch 246/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.8843 - acc: 0.5949 - val_loss: 1.9981 - val_acc: 0.5031\n",
      "Epoch 247/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.8717 - acc: 0.6308 - val_loss: 1.8896 - val_acc: 0.5472\n",
      "Epoch 248/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.8781 - acc: 0.6097 - val_loss: 1.8868 - val_acc: 0.5535\n",
      "Epoch 249/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.8969 - acc: 0.5802 - val_loss: 1.9429 - val_acc: 0.4969\n",
      "Epoch 250/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.8698 - acc: 0.6118 - val_loss: 1.9629 - val_acc: 0.4654\n",
      "Epoch 251/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.8794 - acc: 0.6181 - val_loss: 1.9254 - val_acc: 0.5220\n",
      "Epoch 252/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.8692 - acc: 0.6034 - val_loss: 1.9112 - val_acc: 0.5535\n",
      "Epoch 253/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.8627 - acc: 0.6371 - val_loss: 1.9128 - val_acc: 0.5283\n",
      "Epoch 254/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.8679 - acc: 0.6139 - val_loss: 1.8802 - val_acc: 0.5535\n",
      "Epoch 255/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.8559 - acc: 0.6139 - val_loss: 1.8647 - val_acc: 0.5786\n",
      "Epoch 256/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8731 - acc: 0.6203 - val_loss: 1.9175 - val_acc: 0.5220\n",
      "Epoch 257/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.8376 - acc: 0.6203 - val_loss: 1.8941 - val_acc: 0.5409\n",
      "Epoch 258/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.8614 - acc: 0.6181 - val_loss: 1.9407 - val_acc: 0.5220\n",
      "Epoch 259/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.8939 - acc: 0.6118 - val_loss: 1.9476 - val_acc: 0.5283\n",
      "Epoch 260/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.8475 - acc: 0.6203 - val_loss: 1.8674 - val_acc: 0.5472\n",
      "Epoch 261/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.8481 - acc: 0.6266 - val_loss: 1.8584 - val_acc: 0.5786\n",
      "Epoch 262/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.8768 - acc: 0.6245 - val_loss: 1.9306 - val_acc: 0.5409\n",
      "Epoch 263/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.9067 - acc: 0.5949 - val_loss: 1.9827 - val_acc: 0.4969\n",
      "Epoch 264/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.8667 - acc: 0.6139 - val_loss: 1.8815 - val_acc: 0.5346\n",
      "Epoch 265/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8667 - acc: 0.6287 - val_loss: 1.8904 - val_acc: 0.5472\n",
      "Epoch 266/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.8618 - acc: 0.6118 - val_loss: 1.9075 - val_acc: 0.5094\n",
      "Epoch 267/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.8518 - acc: 0.6266 - val_loss: 1.9002 - val_acc: 0.5786\n",
      "Epoch 268/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.8291 - acc: 0.6245 - val_loss: 1.9036 - val_acc: 0.5723\n",
      "Epoch 269/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8240 - acc: 0.6329 - val_loss: 1.9260 - val_acc: 0.5094\n",
      "Epoch 270/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.8399 - acc: 0.6160 - val_loss: 1.9377 - val_acc: 0.5660\n",
      "Epoch 271/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.8461 - acc: 0.6287 - val_loss: 1.9515 - val_acc: 0.5346\n",
      "Epoch 272/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.8497 - acc: 0.6076 - val_loss: 1.8892 - val_acc: 0.5346\n",
      "Epoch 273/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.8383 - acc: 0.6245 - val_loss: 1.9499 - val_acc: 0.4969\n",
      "Epoch 274/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.8320 - acc: 0.6224 - val_loss: 1.9305 - val_acc: 0.5472\n",
      "Epoch 275/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8201 - acc: 0.6287 - val_loss: 1.8966 - val_acc: 0.5786\n",
      "Epoch 276/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.8312 - acc: 0.6392 - val_loss: 1.9726 - val_acc: 0.5597\n",
      "Epoch 277/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.8378 - acc: 0.6034 - val_loss: 2.0061 - val_acc: 0.5409\n",
      "Epoch 278/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8430 - acc: 0.6181 - val_loss: 1.8919 - val_acc: 0.5220\n",
      "Epoch 279/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.8086 - acc: 0.6435 - val_loss: 1.9273 - val_acc: 0.5597\n",
      "Epoch 280/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.8300 - acc: 0.6224 - val_loss: 1.8742 - val_acc: 0.5535\n",
      "Epoch 281/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.8208 - acc: 0.6350 - val_loss: 1.9079 - val_acc: 0.5409\n",
      "Epoch 282/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.8149 - acc: 0.6392 - val_loss: 1.9356 - val_acc: 0.5283\n",
      "Epoch 283/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.8493 - acc: 0.6181 - val_loss: 1.9591 - val_acc: 0.5094\n",
      "Epoch 284/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.8584 - acc: 0.6118 - val_loss: 1.9030 - val_acc: 0.5346\n",
      "Epoch 285/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.8368 - acc: 0.6055 - val_loss: 1.9663 - val_acc: 0.4780\n",
      "Epoch 286/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.8465 - acc: 0.6055 - val_loss: 1.9464 - val_acc: 0.5535\n",
      "Epoch 287/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 0.8194 - acc: 0.6329 - val_loss: 1.9018 - val_acc: 0.5472\n",
      "Epoch 288/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.8276 - acc: 0.6266 - val_loss: 1.9071 - val_acc: 0.5094\n",
      "Epoch 289/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.8394 - acc: 0.6435 - val_loss: 1.9739 - val_acc: 0.4906\n",
      "Epoch 290/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.8200 - acc: 0.6245 - val_loss: 1.8905 - val_acc: 0.5472\n",
      "Epoch 291/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.8109 - acc: 0.6224 - val_loss: 1.9042 - val_acc: 0.5975\n",
      "Epoch 292/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.8013 - acc: 0.6287 - val_loss: 1.9581 - val_acc: 0.5597\n",
      "Epoch 293/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.8260 - acc: 0.6013 - val_loss: 1.9829 - val_acc: 0.5409\n",
      "Epoch 294/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.8210 - acc: 0.6477 - val_loss: 1.9185 - val_acc: 0.5786\n",
      "Epoch 295/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.8033 - acc: 0.6350 - val_loss: 1.9433 - val_acc: 0.5094\n",
      "Epoch 296/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.8034 - acc: 0.6266 - val_loss: 1.9557 - val_acc: 0.5346\n",
      "Epoch 297/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.8495 - acc: 0.6097 - val_loss: 1.9828 - val_acc: 0.4654\n",
      "Epoch 298/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8218 - acc: 0.6224 - val_loss: 1.8906 - val_acc: 0.5786\n",
      "Epoch 299/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.8119 - acc: 0.6266 - val_loss: 1.9347 - val_acc: 0.4906\n",
      "Epoch 300/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.8207 - acc: 0.6308 - val_loss: 1.9543 - val_acc: 0.5535\n",
      "Epoch 301/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.8278 - acc: 0.6118 - val_loss: 1.9056 - val_acc: 0.5849\n",
      "Epoch 302/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.8081 - acc: 0.6392 - val_loss: 1.9505 - val_acc: 0.5472\n",
      "Epoch 303/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.8336 - acc: 0.6139 - val_loss: 1.8866 - val_acc: 0.5597\n",
      "Epoch 304/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.8062 - acc: 0.6329 - val_loss: 1.9411 - val_acc: 0.5157\n",
      "Epoch 305/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.8156 - acc: 0.6371 - val_loss: 1.8741 - val_acc: 0.5660\n",
      "Epoch 306/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.8081 - acc: 0.6245 - val_loss: 1.9378 - val_acc: 0.5472\n",
      "Epoch 307/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.7930 - acc: 0.6287 - val_loss: 1.9420 - val_acc: 0.5472\n",
      "Epoch 308/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.8065 - acc: 0.6287 - val_loss: 1.9791 - val_acc: 0.5220\n",
      "Epoch 309/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8029 - acc: 0.6392 - val_loss: 1.9242 - val_acc: 0.5157\n",
      "Epoch 310/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.7884 - acc: 0.6392 - val_loss: 1.8831 - val_acc: 0.5723\n",
      "Epoch 311/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.7863 - acc: 0.6371 - val_loss: 1.9453 - val_acc: 0.5472\n",
      "Epoch 312/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.8005 - acc: 0.6329 - val_loss: 1.9168 - val_acc: 0.5031\n",
      "Epoch 313/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.7966 - acc: 0.6245 - val_loss: 1.9108 - val_acc: 0.5220\n",
      "Epoch 314/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.7783 - acc: 0.6456 - val_loss: 1.8889 - val_acc: 0.6038\n",
      "Epoch 315/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.7944 - acc: 0.6329 - val_loss: 1.9446 - val_acc: 0.4906\n",
      "Epoch 316/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.7967 - acc: 0.6139 - val_loss: 1.9341 - val_acc: 0.5535\n",
      "Epoch 317/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.7912 - acc: 0.6308 - val_loss: 1.9343 - val_acc: 0.4843\n",
      "Epoch 318/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.8020 - acc: 0.6477 - val_loss: 1.9337 - val_acc: 0.5535\n",
      "Epoch 319/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.8089 - acc: 0.6076 - val_loss: 1.9592 - val_acc: 0.5283\n",
      "Epoch 320/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.8105 - acc: 0.6034 - val_loss: 1.8875 - val_acc: 0.5660\n",
      "Epoch 321/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7824 - acc: 0.6498 - val_loss: 1.9547 - val_acc: 0.5283\n",
      "Epoch 322/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.7812 - acc: 0.6329 - val_loss: 1.9388 - val_acc: 0.5472\n",
      "Epoch 323/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7896 - acc: 0.6203 - val_loss: 1.9678 - val_acc: 0.5031\n",
      "Epoch 324/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.7634 - acc: 0.6371 - val_loss: 1.9334 - val_acc: 0.5660\n",
      "Epoch 325/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.8096 - acc: 0.6097 - val_loss: 1.9593 - val_acc: 0.5409\n",
      "Epoch 326/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8100 - acc: 0.6076 - val_loss: 1.9495 - val_acc: 0.5535\n",
      "Epoch 327/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.7991 - acc: 0.6203 - val_loss: 1.9441 - val_acc: 0.5535\n",
      "Epoch 328/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.7898 - acc: 0.6266 - val_loss: 1.9225 - val_acc: 0.5283\n",
      "Epoch 329/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7819 - acc: 0.6519 - val_loss: 1.9882 - val_acc: 0.5220\n",
      "Epoch 330/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.7855 - acc: 0.6266 - val_loss: 1.9661 - val_acc: 0.5660\n",
      "Epoch 331/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.7882 - acc: 0.6287 - val_loss: 1.8960 - val_acc: 0.5597\n",
      "Epoch 332/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7728 - acc: 0.6540 - val_loss: 1.9603 - val_acc: 0.5346\n",
      "Epoch 333/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7816 - acc: 0.6245 - val_loss: 1.9823 - val_acc: 0.5535\n",
      "Epoch 334/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8304 - acc: 0.6245 - val_loss: 1.9191 - val_acc: 0.5786\n",
      "Epoch 335/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.8079 - acc: 0.6097 - val_loss: 1.9131 - val_acc: 0.5220\n",
      "Epoch 336/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.8068 - acc: 0.6414 - val_loss: 1.9603 - val_acc: 0.5157\n",
      "Epoch 337/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.7997 - acc: 0.6477 - val_loss: 1.9344 - val_acc: 0.5597\n",
      "Epoch 338/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7775 - acc: 0.6245 - val_loss: 1.9652 - val_acc: 0.5472\n",
      "Epoch 339/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.7460 - acc: 0.6477 - val_loss: 1.9239 - val_acc: 0.5472\n",
      "Epoch 340/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.7677 - acc: 0.6435 - val_loss: 2.0154 - val_acc: 0.5849\n",
      "Epoch 341/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.7770 - acc: 0.6224 - val_loss: 1.9461 - val_acc: 0.5031\n",
      "Epoch 342/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7628 - acc: 0.6266 - val_loss: 1.9204 - val_acc: 0.5220\n",
      "Epoch 343/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.7595 - acc: 0.6498 - val_loss: 1.9539 - val_acc: 0.5472\n",
      "Epoch 344/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7540 - acc: 0.6519 - val_loss: 1.9380 - val_acc: 0.5157\n",
      "Epoch 345/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7852 - acc: 0.6224 - val_loss: 1.9367 - val_acc: 0.5409\n",
      "Epoch 346/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.7611 - acc: 0.6414 - val_loss: 1.9257 - val_acc: 0.5849\n",
      "Epoch 347/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.7575 - acc: 0.6329 - val_loss: 1.9370 - val_acc: 0.5220\n",
      "Epoch 348/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.7639 - acc: 0.6371 - val_loss: 2.0304 - val_acc: 0.5220\n",
      "Epoch 349/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.7630 - acc: 0.6224 - val_loss: 1.9352 - val_acc: 0.5723\n",
      "Epoch 350/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.7657 - acc: 0.6287 - val_loss: 1.9242 - val_acc: 0.5597\n",
      "Epoch 351/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.7748 - acc: 0.6519 - val_loss: 1.9139 - val_acc: 0.5472\n",
      "Epoch 352/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.8069 - acc: 0.6245 - val_loss: 1.9734 - val_acc: 0.5283\n",
      "Epoch 353/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.7750 - acc: 0.6435 - val_loss: 1.9908 - val_acc: 0.5409\n",
      "Epoch 354/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.7857 - acc: 0.6519 - val_loss: 1.9764 - val_acc: 0.5535\n",
      "Epoch 355/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7563 - acc: 0.6519 - val_loss: 1.9979 - val_acc: 0.5535\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/474 [==============================] - 0s 106us/step - loss: 0.7461 - acc: 0.6540 - val_loss: 1.9691 - val_acc: 0.5346\n",
      "Epoch 357/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7627 - acc: 0.6456 - val_loss: 1.9804 - val_acc: 0.5849\n",
      "Epoch 358/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.7895 - acc: 0.6160 - val_loss: 1.9384 - val_acc: 0.5157\n",
      "Epoch 359/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.7732 - acc: 0.6498 - val_loss: 1.9158 - val_acc: 0.5786\n",
      "Epoch 360/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.7682 - acc: 0.6266 - val_loss: 2.0111 - val_acc: 0.5094\n",
      "Epoch 361/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.7700 - acc: 0.6203 - val_loss: 1.9627 - val_acc: 0.5535\n",
      "Epoch 362/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.7476 - acc: 0.6329 - val_loss: 1.9316 - val_acc: 0.5535\n",
      "Epoch 363/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.7623 - acc: 0.6350 - val_loss: 1.9424 - val_acc: 0.5409\n",
      "Epoch 364/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.7639 - acc: 0.6371 - val_loss: 2.0177 - val_acc: 0.5535\n",
      "Epoch 365/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.7782 - acc: 0.6160 - val_loss: 2.0128 - val_acc: 0.5597\n",
      "Epoch 366/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.7450 - acc: 0.6350 - val_loss: 1.9738 - val_acc: 0.5346\n",
      "Epoch 367/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.7528 - acc: 0.6498 - val_loss: 1.9428 - val_acc: 0.5094\n",
      "Epoch 368/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.7486 - acc: 0.6456 - val_loss: 1.9423 - val_acc: 0.5220\n",
      "Epoch 369/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.7592 - acc: 0.6287 - val_loss: 1.9720 - val_acc: 0.5535\n",
      "Epoch 370/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7457 - acc: 0.6181 - val_loss: 1.9787 - val_acc: 0.5157\n",
      "Epoch 371/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.7743 - acc: 0.6266 - val_loss: 1.9692 - val_acc: 0.5346\n",
      "Epoch 372/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7676 - acc: 0.6245 - val_loss: 1.9663 - val_acc: 0.5283\n",
      "Epoch 373/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.7537 - acc: 0.6646 - val_loss: 1.9773 - val_acc: 0.5409\n",
      "Epoch 374/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.7549 - acc: 0.6561 - val_loss: 2.0014 - val_acc: 0.5346\n",
      "Epoch 375/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.8087 - acc: 0.6245 - val_loss: 1.9300 - val_acc: 0.5283\n",
      "Epoch 376/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7794 - acc: 0.6160 - val_loss: 2.0067 - val_acc: 0.5283\n",
      "Epoch 377/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.7558 - acc: 0.6224 - val_loss: 1.9804 - val_acc: 0.5220\n",
      "Epoch 378/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.7497 - acc: 0.6329 - val_loss: 1.9535 - val_acc: 0.5786\n",
      "Epoch 379/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7611 - acc: 0.6245 - val_loss: 1.9803 - val_acc: 0.5283\n",
      "Epoch 380/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.7434 - acc: 0.6350 - val_loss: 1.9602 - val_acc: 0.5535\n",
      "Epoch 381/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.7342 - acc: 0.6582 - val_loss: 1.9650 - val_acc: 0.5535\n",
      "Epoch 382/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.7443 - acc: 0.6308 - val_loss: 1.9863 - val_acc: 0.5535\n",
      "Epoch 383/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.7532 - acc: 0.6329 - val_loss: 1.9495 - val_acc: 0.5660\n",
      "Epoch 384/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7479 - acc: 0.6287 - val_loss: 1.9537 - val_acc: 0.5975\n",
      "Epoch 385/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.7214 - acc: 0.6688 - val_loss: 1.9823 - val_acc: 0.5283\n",
      "Epoch 386/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 0.7361 - acc: 0.6350 - val_loss: 1.9987 - val_acc: 0.5283\n",
      "Epoch 387/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.7462 - acc: 0.6435 - val_loss: 2.0393 - val_acc: 0.5220\n",
      "Epoch 388/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.7447 - acc: 0.6435 - val_loss: 1.9937 - val_acc: 0.5723\n",
      "Epoch 389/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.7491 - acc: 0.6603 - val_loss: 2.0033 - val_acc: 0.4969\n",
      "Epoch 390/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.7409 - acc: 0.6456 - val_loss: 1.9469 - val_acc: 0.6101\n",
      "Epoch 391/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.7205 - acc: 0.6688 - val_loss: 1.9667 - val_acc: 0.5597\n",
      "Epoch 392/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.7192 - acc: 0.6519 - val_loss: 1.9728 - val_acc: 0.5409\n",
      "Epoch 393/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.7291 - acc: 0.6498 - val_loss: 1.9819 - val_acc: 0.5472\n",
      "Epoch 394/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.7343 - acc: 0.6477 - val_loss: 1.9807 - val_acc: 0.5849\n",
      "Epoch 395/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.7397 - acc: 0.6392 - val_loss: 1.9729 - val_acc: 0.5849\n",
      "Epoch 396/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.7261 - acc: 0.6224 - val_loss: 1.9656 - val_acc: 0.5723\n",
      "Epoch 397/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.7292 - acc: 0.6540 - val_loss: 1.9853 - val_acc: 0.5786\n",
      "Epoch 398/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.7360 - acc: 0.6435 - val_loss: 1.9637 - val_acc: 0.5849\n",
      "Epoch 399/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.7342 - acc: 0.6519 - val_loss: 2.0089 - val_acc: 0.5031\n",
      "Epoch 400/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7533 - acc: 0.6624 - val_loss: 1.9659 - val_acc: 0.5786\n",
      "Epoch 401/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7619 - acc: 0.6540 - val_loss: 1.9921 - val_acc: 0.5346\n",
      "Epoch 402/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.7452 - acc: 0.6308 - val_loss: 2.0256 - val_acc: 0.5220\n",
      "Epoch 403/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.7458 - acc: 0.6477 - val_loss: 2.0464 - val_acc: 0.5094\n",
      "Epoch 404/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.7438 - acc: 0.6392 - val_loss: 1.9990 - val_acc: 0.5723\n",
      "Epoch 405/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.7300 - acc: 0.6477 - val_loss: 1.9888 - val_acc: 0.5849\n",
      "Epoch 406/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.7728 - acc: 0.6371 - val_loss: 1.9637 - val_acc: 0.5283\n",
      "Epoch 407/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.7493 - acc: 0.6456 - val_loss: 2.0175 - val_acc: 0.5283\n",
      "Epoch 408/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.7493 - acc: 0.6118 - val_loss: 1.9962 - val_acc: 0.5535\n",
      "Epoch 409/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.7207 - acc: 0.6414 - val_loss: 2.0109 - val_acc: 0.5535\n",
      "Epoch 410/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7222 - acc: 0.6582 - val_loss: 1.9846 - val_acc: 0.5409\n",
      "Epoch 411/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.7273 - acc: 0.6456 - val_loss: 2.0131 - val_acc: 0.5220\n",
      "Epoch 412/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.7536 - acc: 0.6139 - val_loss: 2.0028 - val_acc: 0.5409\n",
      "Epoch 413/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.7332 - acc: 0.6519 - val_loss: 2.0034 - val_acc: 0.5975\n",
      "Epoch 414/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.7482 - acc: 0.6287 - val_loss: 2.0004 - val_acc: 0.5472\n",
      "Epoch 415/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.7413 - acc: 0.6392 - val_loss: 1.9540 - val_acc: 0.5157\n",
      "Epoch 416/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.7436 - acc: 0.6603 - val_loss: 1.9909 - val_acc: 0.5597\n",
      "Epoch 417/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7292 - acc: 0.6519 - val_loss: 2.0221 - val_acc: 0.5157\n",
      "Epoch 418/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.7157 - acc: 0.6667 - val_loss: 1.9638 - val_acc: 0.5786\n",
      "Epoch 419/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7187 - acc: 0.6667 - val_loss: 1.9758 - val_acc: 0.5597\n",
      "Epoch 420/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.7134 - acc: 0.6392 - val_loss: 1.9840 - val_acc: 0.5723\n",
      "Epoch 421/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.7200 - acc: 0.6414 - val_loss: 1.9881 - val_acc: 0.5535\n",
      "Epoch 422/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7081 - acc: 0.6540 - val_loss: 2.0306 - val_acc: 0.5786\n",
      "Epoch 423/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.7130 - acc: 0.6688 - val_loss: 1.9240 - val_acc: 0.5660\n",
      "Epoch 424/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.7101 - acc: 0.6371 - val_loss: 1.9685 - val_acc: 0.5975\n",
      "Epoch 425/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.7169 - acc: 0.6414 - val_loss: 1.9997 - val_acc: 0.5220\n",
      "Epoch 426/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.7145 - acc: 0.6603 - val_loss: 2.0266 - val_acc: 0.5472\n",
      "Epoch 427/1000\n",
      "474/474 [==============================] - 0s 101us/step - loss: 0.7107 - acc: 0.6519 - val_loss: 1.9714 - val_acc: 0.5723\n",
      "Epoch 428/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6998 - acc: 0.6561 - val_loss: 1.9713 - val_acc: 0.5597\n",
      "Epoch 429/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.7145 - acc: 0.6561 - val_loss: 2.0589 - val_acc: 0.5283\n",
      "Epoch 430/1000\n",
      "474/474 [==============================] - 0s 96us/step - loss: 0.6950 - acc: 0.6709 - val_loss: 2.0444 - val_acc: 0.5786\n",
      "Epoch 431/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.7635 - acc: 0.6371 - val_loss: 1.9949 - val_acc: 0.5220\n",
      "Epoch 432/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.7821 - acc: 0.6181 - val_loss: 2.0505 - val_acc: 0.5849\n",
      "Epoch 433/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.7702 - acc: 0.6456 - val_loss: 1.9589 - val_acc: 0.5472\n",
      "Epoch 434/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.7192 - acc: 0.6646 - val_loss: 2.0194 - val_acc: 0.5409\n",
      "Epoch 435/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7230 - acc: 0.6350 - val_loss: 2.0120 - val_acc: 0.5220\n",
      "Epoch 436/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.7251 - acc: 0.6582 - val_loss: 1.9778 - val_acc: 0.5283\n",
      "Epoch 437/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.7270 - acc: 0.6561 - val_loss: 2.0033 - val_acc: 0.5409\n",
      "Epoch 438/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.7460 - acc: 0.6540 - val_loss: 1.9923 - val_acc: 0.5220\n",
      "Epoch 439/1000\n",
      "474/474 [==============================] - 0s 101us/step - loss: 0.6896 - acc: 0.6772 - val_loss: 2.0064 - val_acc: 0.5409\n",
      "Epoch 440/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.7025 - acc: 0.6561 - val_loss: 2.0208 - val_acc: 0.5283\n",
      "Epoch 441/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6968 - acc: 0.6646 - val_loss: 1.9762 - val_acc: 0.5597\n",
      "Epoch 442/1000\n",
      "474/474 [==============================] - 0s 101us/step - loss: 0.7016 - acc: 0.6519 - val_loss: 2.0130 - val_acc: 0.5346\n",
      "Epoch 443/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.7168 - acc: 0.6540 - val_loss: 2.0198 - val_acc: 0.5660\n",
      "Epoch 444/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.7224 - acc: 0.6414 - val_loss: 2.0117 - val_acc: 0.5597\n",
      "Epoch 445/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7064 - acc: 0.6540 - val_loss: 2.0060 - val_acc: 0.4906\n",
      "Epoch 446/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6995 - acc: 0.6624 - val_loss: 2.0610 - val_acc: 0.5660\n",
      "Epoch 447/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.7161 - acc: 0.6350 - val_loss: 1.9767 - val_acc: 0.5849\n",
      "Epoch 448/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6807 - acc: 0.6667 - val_loss: 2.0146 - val_acc: 0.5535\n",
      "Epoch 449/1000\n",
      "474/474 [==============================] - 0s 101us/step - loss: 0.7106 - acc: 0.6435 - val_loss: 2.0002 - val_acc: 0.5912\n",
      "Epoch 450/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.7169 - acc: 0.6435 - val_loss: 2.0068 - val_acc: 0.5912\n",
      "Epoch 451/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.7365 - acc: 0.6435 - val_loss: 2.0413 - val_acc: 0.5157\n",
      "Epoch 452/1000\n",
      "474/474 [==============================] - 0s 99us/step - loss: 0.7076 - acc: 0.6498 - val_loss: 1.9632 - val_acc: 0.5346\n",
      "Epoch 453/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6967 - acc: 0.6603 - val_loss: 2.0029 - val_acc: 0.5535\n",
      "Epoch 454/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6990 - acc: 0.6435 - val_loss: 2.0890 - val_acc: 0.5283\n",
      "Epoch 455/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.7872 - acc: 0.6414 - val_loss: 2.0502 - val_acc: 0.5660\n",
      "Epoch 456/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.7593 - acc: 0.6582 - val_loss: 1.9986 - val_acc: 0.5094\n",
      "Epoch 457/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.7339 - acc: 0.6561 - val_loss: 2.0476 - val_acc: 0.5157\n",
      "Epoch 458/1000\n",
      "474/474 [==============================] - 0s 101us/step - loss: 0.7071 - acc: 0.6603 - val_loss: 1.9280 - val_acc: 0.5912\n",
      "Epoch 459/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.7026 - acc: 0.6603 - val_loss: 1.9739 - val_acc: 0.5220\n",
      "Epoch 460/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6775 - acc: 0.6751 - val_loss: 1.9877 - val_acc: 0.5472\n",
      "Epoch 461/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6916 - acc: 0.6561 - val_loss: 1.9798 - val_acc: 0.5723\n",
      "Epoch 462/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7508 - acc: 0.6477 - val_loss: 2.0620 - val_acc: 0.5220\n",
      "Epoch 463/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6962 - acc: 0.6709 - val_loss: 1.9509 - val_acc: 0.6101\n",
      "Epoch 464/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.7032 - acc: 0.6498 - val_loss: 2.0088 - val_acc: 0.5660\n",
      "Epoch 465/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.7052 - acc: 0.6477 - val_loss: 1.9922 - val_acc: 0.5283\n",
      "Epoch 466/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.6892 - acc: 0.6498 - val_loss: 1.9861 - val_acc: 0.5535\n",
      "Epoch 467/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6848 - acc: 0.6730 - val_loss: 2.0085 - val_acc: 0.5472\n",
      "Epoch 468/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.7167 - acc: 0.6350 - val_loss: 1.9784 - val_acc: 0.5472\n",
      "Epoch 469/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7062 - acc: 0.6435 - val_loss: 2.0179 - val_acc: 0.5409\n",
      "Epoch 470/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.7017 - acc: 0.6582 - val_loss: 2.0288 - val_acc: 0.5283\n",
      "Epoch 471/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.6866 - acc: 0.6414 - val_loss: 2.0107 - val_acc: 0.5660\n",
      "Epoch 472/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.7087 - acc: 0.6498 - val_loss: 2.0513 - val_acc: 0.5723\n",
      "Epoch 473/1000\n",
      "474/474 [==============================] - 0s 138us/step - loss: 0.7091 - acc: 0.6582 - val_loss: 2.0030 - val_acc: 0.5849\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/474 [==============================] - 0s 103us/step - loss: 0.7069 - acc: 0.6624 - val_loss: 2.0126 - val_acc: 0.4906\n",
      "Epoch 475/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.6686 - acc: 0.6646 - val_loss: 1.9868 - val_acc: 0.5912\n",
      "Epoch 476/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.6831 - acc: 0.6582 - val_loss: 2.0045 - val_acc: 0.5283\n",
      "Epoch 477/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6745 - acc: 0.6498 - val_loss: 2.0327 - val_acc: 0.5597\n",
      "Epoch 478/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6916 - acc: 0.6392 - val_loss: 2.0028 - val_acc: 0.5220\n",
      "Epoch 479/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.7050 - acc: 0.6435 - val_loss: 1.9761 - val_acc: 0.5472\n",
      "Epoch 480/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.6976 - acc: 0.6350 - val_loss: 2.0018 - val_acc: 0.5472\n",
      "Epoch 481/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.7075 - acc: 0.6498 - val_loss: 1.9936 - val_acc: 0.5409\n",
      "Epoch 482/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6883 - acc: 0.6498 - val_loss: 1.9783 - val_acc: 0.5409\n",
      "Epoch 483/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6609 - acc: 0.6624 - val_loss: 1.9770 - val_acc: 0.5786\n",
      "Epoch 484/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6820 - acc: 0.6582 - val_loss: 2.0019 - val_acc: 0.5031\n",
      "Epoch 485/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6716 - acc: 0.6582 - val_loss: 2.0777 - val_acc: 0.5535\n",
      "Epoch 486/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.6843 - acc: 0.6646 - val_loss: 2.0240 - val_acc: 0.4969\n",
      "Epoch 487/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.7056 - acc: 0.6498 - val_loss: 1.9665 - val_acc: 0.5786\n",
      "Epoch 488/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.7261 - acc: 0.6498 - val_loss: 1.9911 - val_acc: 0.5472\n",
      "Epoch 489/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6717 - acc: 0.6730 - val_loss: 2.0095 - val_acc: 0.5723\n",
      "Epoch 490/1000\n",
      "474/474 [==============================] - 0s 99us/step - loss: 0.6725 - acc: 0.6603 - val_loss: 1.9715 - val_acc: 0.5723\n",
      "Epoch 491/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6984 - acc: 0.6772 - val_loss: 2.0644 - val_acc: 0.5535\n",
      "Epoch 492/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 0.7023 - acc: 0.6498 - val_loss: 1.9949 - val_acc: 0.5597\n",
      "Epoch 493/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.7220 - acc: 0.6561 - val_loss: 2.0873 - val_acc: 0.5283\n",
      "Epoch 494/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.7191 - acc: 0.6456 - val_loss: 1.9787 - val_acc: 0.5975\n",
      "Epoch 495/1000\n",
      "474/474 [==============================] - 0s 97us/step - loss: 0.7032 - acc: 0.6646 - val_loss: 2.0208 - val_acc: 0.5220\n",
      "Epoch 496/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.6802 - acc: 0.6603 - val_loss: 2.0150 - val_acc: 0.5472\n",
      "Epoch 497/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6788 - acc: 0.6772 - val_loss: 2.0006 - val_acc: 0.5409\n",
      "Epoch 498/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6763 - acc: 0.6688 - val_loss: 2.0537 - val_acc: 0.5346\n",
      "Epoch 499/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6662 - acc: 0.6519 - val_loss: 1.9867 - val_acc: 0.5660\n",
      "Epoch 500/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.6743 - acc: 0.6878 - val_loss: 1.9928 - val_acc: 0.5472\n",
      "Epoch 501/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6796 - acc: 0.6730 - val_loss: 2.0516 - val_acc: 0.5409\n",
      "Epoch 502/1000\n",
      "474/474 [==============================] - 0s 101us/step - loss: 0.6943 - acc: 0.6730 - val_loss: 2.0142 - val_acc: 0.5535\n",
      "Epoch 503/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6757 - acc: 0.6540 - val_loss: 2.0567 - val_acc: 0.5220\n",
      "Epoch 504/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.6987 - acc: 0.6540 - val_loss: 1.9884 - val_acc: 0.5786\n",
      "Epoch 505/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6905 - acc: 0.6498 - val_loss: 2.0044 - val_acc: 0.5597\n",
      "Epoch 506/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.6954 - acc: 0.6519 - val_loss: 2.0365 - val_acc: 0.5660\n",
      "Epoch 507/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6746 - acc: 0.6751 - val_loss: 2.0099 - val_acc: 0.5472\n",
      "Epoch 508/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6796 - acc: 0.6477 - val_loss: 2.0613 - val_acc: 0.5597\n",
      "Epoch 509/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6903 - acc: 0.6540 - val_loss: 2.0550 - val_acc: 0.5283\n",
      "Epoch 510/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6851 - acc: 0.6392 - val_loss: 2.0495 - val_acc: 0.5472\n",
      "Epoch 511/1000\n",
      "474/474 [==============================] - 0s 98us/step - loss: 0.7016 - acc: 0.6646 - val_loss: 1.9852 - val_acc: 0.5409\n",
      "Epoch 512/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6859 - acc: 0.6688 - val_loss: 2.0221 - val_acc: 0.5535\n",
      "Epoch 513/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6762 - acc: 0.6519 - val_loss: 2.0001 - val_acc: 0.5597\n",
      "Epoch 514/1000\n",
      "474/474 [==============================] - 0s 101us/step - loss: 0.6793 - acc: 0.6498 - val_loss: 2.0302 - val_acc: 0.5346\n",
      "Epoch 515/1000\n",
      "474/474 [==============================] - 0s 99us/step - loss: 0.6578 - acc: 0.6793 - val_loss: 2.0095 - val_acc: 0.5283\n",
      "Epoch 516/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6828 - acc: 0.6540 - val_loss: 2.0017 - val_acc: 0.5409\n",
      "Epoch 517/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.6785 - acc: 0.6603 - val_loss: 2.0498 - val_acc: 0.5346\n",
      "Epoch 518/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6888 - acc: 0.6688 - val_loss: 2.0423 - val_acc: 0.5409\n",
      "Epoch 519/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6883 - acc: 0.6414 - val_loss: 2.0356 - val_acc: 0.5409\n",
      "Epoch 520/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6712 - acc: 0.6646 - val_loss: 2.0228 - val_acc: 0.5220\n",
      "Epoch 521/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6837 - acc: 0.6646 - val_loss: 2.0419 - val_acc: 0.4969\n",
      "Epoch 522/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.7142 - acc: 0.6498 - val_loss: 2.0616 - val_acc: 0.5409\n",
      "Epoch 523/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6816 - acc: 0.6688 - val_loss: 2.0149 - val_acc: 0.5283\n",
      "Epoch 524/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.6830 - acc: 0.6646 - val_loss: 2.0416 - val_acc: 0.5849\n",
      "Epoch 525/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.7056 - acc: 0.6561 - val_loss: 2.0553 - val_acc: 0.5220\n",
      "Epoch 526/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.6774 - acc: 0.6624 - val_loss: 2.0144 - val_acc: 0.5597\n",
      "Epoch 527/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6624 - acc: 0.6646 - val_loss: 1.9899 - val_acc: 0.5157\n",
      "Epoch 528/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.6699 - acc: 0.6540 - val_loss: 2.0364 - val_acc: 0.5597\n",
      "Epoch 529/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6885 - acc: 0.6414 - val_loss: 2.0958 - val_acc: 0.4969\n",
      "Epoch 530/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6809 - acc: 0.6646 - val_loss: 1.9960 - val_acc: 0.5346\n",
      "Epoch 531/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6700 - acc: 0.6814 - val_loss: 2.0725 - val_acc: 0.5472\n",
      "Epoch 532/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6506 - acc: 0.6667 - val_loss: 2.0003 - val_acc: 0.5660\n",
      "Epoch 533/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.6466 - acc: 0.6646 - val_loss: 2.0003 - val_acc: 0.5220\n",
      "Epoch 534/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6597 - acc: 0.6603 - val_loss: 2.0310 - val_acc: 0.5283\n",
      "Epoch 535/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6858 - acc: 0.6814 - val_loss: 2.0317 - val_acc: 0.5220\n",
      "Epoch 536/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.7037 - acc: 0.6477 - val_loss: 2.0543 - val_acc: 0.5157\n",
      "Epoch 537/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.6672 - acc: 0.6730 - val_loss: 2.0392 - val_acc: 0.5346\n",
      "Epoch 538/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6592 - acc: 0.6667 - val_loss: 2.0223 - val_acc: 0.5409\n",
      "Epoch 539/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6705 - acc: 0.6646 - val_loss: 1.9969 - val_acc: 0.4969\n",
      "Epoch 540/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.6972 - acc: 0.6603 - val_loss: 2.0392 - val_acc: 0.5283\n",
      "Epoch 541/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6648 - acc: 0.6561 - val_loss: 1.9915 - val_acc: 0.5975\n",
      "Epoch 542/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.6838 - acc: 0.6498 - val_loss: 1.9917 - val_acc: 0.5031\n",
      "Epoch 543/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6664 - acc: 0.6561 - val_loss: 2.0452 - val_acc: 0.5535\n",
      "Epoch 544/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6648 - acc: 0.6793 - val_loss: 2.0972 - val_acc: 0.5535\n",
      "Epoch 545/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6747 - acc: 0.6582 - val_loss: 1.9868 - val_acc: 0.5723\n",
      "Epoch 546/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6693 - acc: 0.6688 - val_loss: 2.0247 - val_acc: 0.5535\n",
      "Epoch 547/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6662 - acc: 0.6709 - val_loss: 1.9970 - val_acc: 0.5535\n",
      "Epoch 548/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6610 - acc: 0.6624 - val_loss: 2.0328 - val_acc: 0.5220\n",
      "Epoch 549/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6762 - acc: 0.6540 - val_loss: 1.9893 - val_acc: 0.5220\n",
      "Epoch 550/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6725 - acc: 0.6624 - val_loss: 2.0908 - val_acc: 0.5409\n",
      "Epoch 551/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6522 - acc: 0.6709 - val_loss: 2.0637 - val_acc: 0.4969\n",
      "Epoch 552/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6826 - acc: 0.6772 - val_loss: 2.0233 - val_acc: 0.5157\n",
      "Epoch 553/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6624 - acc: 0.6667 - val_loss: 2.0104 - val_acc: 0.5535\n",
      "Epoch 554/1000\n",
      "474/474 [==============================] - 0s 98us/step - loss: 0.6626 - acc: 0.6519 - val_loss: 2.0148 - val_acc: 0.5346\n",
      "Epoch 555/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6451 - acc: 0.6561 - val_loss: 2.0455 - val_acc: 0.5535\n",
      "Epoch 556/1000\n",
      "474/474 [==============================] - 0s 97us/step - loss: 0.6699 - acc: 0.6772 - val_loss: 2.0199 - val_acc: 0.5409\n",
      "Epoch 557/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6813 - acc: 0.6646 - val_loss: 2.0154 - val_acc: 0.5346\n",
      "Epoch 558/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6707 - acc: 0.6688 - val_loss: 2.0816 - val_acc: 0.5912\n",
      "Epoch 559/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.6955 - acc: 0.6603 - val_loss: 1.9916 - val_acc: 0.5597\n",
      "Epoch 560/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6607 - acc: 0.6667 - val_loss: 2.0606 - val_acc: 0.5472\n",
      "Epoch 561/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.6840 - acc: 0.6477 - val_loss: 1.9963 - val_acc: 0.5094\n",
      "Epoch 562/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6984 - acc: 0.6456 - val_loss: 2.0400 - val_acc: 0.5472\n",
      "Epoch 563/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6453 - acc: 0.6667 - val_loss: 2.0317 - val_acc: 0.5597\n",
      "Epoch 564/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6600 - acc: 0.6751 - val_loss: 2.0223 - val_acc: 0.5409\n",
      "Epoch 565/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.6365 - acc: 0.6793 - val_loss: 2.0146 - val_acc: 0.5472\n",
      "Epoch 566/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6466 - acc: 0.6688 - val_loss: 2.0132 - val_acc: 0.5409\n",
      "Epoch 567/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6522 - acc: 0.6688 - val_loss: 1.9878 - val_acc: 0.5786\n",
      "Epoch 568/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6733 - acc: 0.6688 - val_loss: 2.0194 - val_acc: 0.5094\n",
      "Epoch 569/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6870 - acc: 0.6603 - val_loss: 1.9981 - val_acc: 0.5535\n",
      "Epoch 570/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.6617 - acc: 0.6667 - val_loss: 2.0240 - val_acc: 0.5346\n",
      "Epoch 571/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.6735 - acc: 0.6646 - val_loss: 2.0243 - val_acc: 0.5409\n",
      "Epoch 572/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6880 - acc: 0.6667 - val_loss: 2.0478 - val_acc: 0.5597\n",
      "Epoch 573/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6822 - acc: 0.6646 - val_loss: 2.0734 - val_acc: 0.4843\n",
      "Epoch 574/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.6566 - acc: 0.6688 - val_loss: 1.9957 - val_acc: 0.5723\n",
      "Epoch 575/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.6676 - acc: 0.6793 - val_loss: 2.0691 - val_acc: 0.5283\n",
      "Epoch 576/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6793 - acc: 0.6540 - val_loss: 2.0208 - val_acc: 0.5409\n",
      "Epoch 577/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6824 - acc: 0.6730 - val_loss: 1.9815 - val_acc: 0.5723\n",
      "Epoch 578/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6687 - acc: 0.6603 - val_loss: 2.0528 - val_acc: 0.5786\n",
      "Epoch 579/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6502 - acc: 0.6835 - val_loss: 2.0246 - val_acc: 0.5220\n",
      "Epoch 580/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6918 - acc: 0.6414 - val_loss: 2.0127 - val_acc: 0.5031\n",
      "Epoch 581/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.6512 - acc: 0.6878 - val_loss: 2.0032 - val_acc: 0.5220\n",
      "Epoch 582/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 0.6820 - acc: 0.6350 - val_loss: 2.0200 - val_acc: 0.5283\n",
      "Epoch 583/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.6356 - acc: 0.6730 - val_loss: 2.0253 - val_acc: 0.5535\n",
      "Epoch 584/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 0.6605 - acc: 0.6646 - val_loss: 2.0478 - val_acc: 0.5346\n",
      "Epoch 585/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.6443 - acc: 0.6772 - val_loss: 2.0366 - val_acc: 0.5031\n",
      "Epoch 586/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 0.6374 - acc: 0.6688 - val_loss: 2.0109 - val_acc: 0.5220\n",
      "Epoch 587/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 0.6416 - acc: 0.6772 - val_loss: 2.0204 - val_acc: 0.5597\n",
      "Epoch 588/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 0.6262 - acc: 0.6878 - val_loss: 1.9775 - val_acc: 0.5472\n",
      "Epoch 589/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.6372 - acc: 0.6730 - val_loss: 2.0228 - val_acc: 0.5535\n",
      "Epoch 590/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6485 - acc: 0.6730 - val_loss: 1.9948 - val_acc: 0.6101\n",
      "Epoch 591/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6525 - acc: 0.6646 - val_loss: 2.0256 - val_acc: 0.5031\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/474 [==============================] - 0s 113us/step - loss: 0.6367 - acc: 0.6582 - val_loss: 2.0244 - val_acc: 0.5409\n",
      "Epoch 593/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6387 - acc: 0.6835 - val_loss: 2.0501 - val_acc: 0.5157\n",
      "Epoch 594/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6715 - acc: 0.6751 - val_loss: 2.0368 - val_acc: 0.5346\n",
      "Epoch 595/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6556 - acc: 0.6730 - val_loss: 2.0508 - val_acc: 0.4906\n",
      "Epoch 596/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6672 - acc: 0.6730 - val_loss: 1.9799 - val_acc: 0.5346\n",
      "Epoch 597/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6431 - acc: 0.6814 - val_loss: 2.0447 - val_acc: 0.5094\n",
      "Epoch 598/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.6383 - acc: 0.6857 - val_loss: 1.9656 - val_acc: 0.6101\n",
      "Epoch 599/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.6587 - acc: 0.6498 - val_loss: 2.0081 - val_acc: 0.5031\n",
      "Epoch 600/1000\n",
      "474/474 [==============================] - 0s 154us/step - loss: 0.6544 - acc: 0.6667 - val_loss: 2.0679 - val_acc: 0.5472\n",
      "Epoch 601/1000\n",
      "474/474 [==============================] - 0s 139us/step - loss: 0.6425 - acc: 0.6878 - val_loss: 2.0606 - val_acc: 0.5220\n",
      "Epoch 602/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 0.6611 - acc: 0.6498 - val_loss: 2.0645 - val_acc: 0.5220\n",
      "Epoch 603/1000\n",
      "474/474 [==============================] - 0s 133us/step - loss: 0.6807 - acc: 0.6477 - val_loss: 2.0339 - val_acc: 0.5472\n",
      "Epoch 604/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.6528 - acc: 0.6624 - val_loss: 2.0681 - val_acc: 0.5409\n",
      "Epoch 605/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6598 - acc: 0.6456 - val_loss: 2.0182 - val_acc: 0.5283\n",
      "Epoch 606/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.6469 - acc: 0.6688 - val_loss: 2.0577 - val_acc: 0.5031\n",
      "Epoch 607/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6616 - acc: 0.6646 - val_loss: 2.0812 - val_acc: 0.5031\n",
      "Epoch 608/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.6439 - acc: 0.6793 - val_loss: 2.0573 - val_acc: 0.5409\n",
      "Epoch 609/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6526 - acc: 0.6561 - val_loss: 1.9901 - val_acc: 0.5660\n",
      "Epoch 610/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.6435 - acc: 0.6814 - val_loss: 2.0342 - val_acc: 0.5535\n",
      "Epoch 611/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6439 - acc: 0.6667 - val_loss: 2.0857 - val_acc: 0.4906\n",
      "Epoch 612/1000\n",
      "474/474 [==============================] - 0s 150us/step - loss: 0.6814 - acc: 0.6688 - val_loss: 1.9851 - val_acc: 0.5597\n",
      "Epoch 613/1000\n",
      "474/474 [==============================] - 0s 146us/step - loss: 0.6570 - acc: 0.6519 - val_loss: 2.0373 - val_acc: 0.4654\n",
      "Epoch 614/1000\n",
      "474/474 [==============================] - 0s 166us/step - loss: 0.6507 - acc: 0.6878 - val_loss: 2.0019 - val_acc: 0.5094\n",
      "Epoch 615/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.6577 - acc: 0.6709 - val_loss: 2.0718 - val_acc: 0.5346\n",
      "Epoch 616/1000\n",
      "474/474 [==============================] - 0s 133us/step - loss: 0.6762 - acc: 0.6498 - val_loss: 2.0210 - val_acc: 0.5409\n",
      "Epoch 617/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6636 - acc: 0.6624 - val_loss: 2.0099 - val_acc: 0.5409\n",
      "Epoch 618/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.6429 - acc: 0.6793 - val_loss: 1.9854 - val_acc: 0.5786\n",
      "Epoch 619/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.6512 - acc: 0.6688 - val_loss: 2.1392 - val_acc: 0.5094\n",
      "Epoch 620/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6909 - acc: 0.6624 - val_loss: 2.0147 - val_acc: 0.5346\n",
      "Epoch 621/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.6747 - acc: 0.6540 - val_loss: 2.0482 - val_acc: 0.5283\n",
      "Epoch 622/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.6608 - acc: 0.6498 - val_loss: 2.0265 - val_acc: 0.5283\n",
      "Epoch 623/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6429 - acc: 0.6688 - val_loss: 2.0458 - val_acc: 0.4969\n",
      "Epoch 624/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.6339 - acc: 0.6899 - val_loss: 2.0600 - val_acc: 0.5094\n",
      "Epoch 625/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.6604 - acc: 0.6920 - val_loss: 2.0219 - val_acc: 0.5346\n",
      "Epoch 626/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 0.6543 - acc: 0.6730 - val_loss: 2.0038 - val_acc: 0.5535\n",
      "Epoch 627/1000\n",
      "474/474 [==============================] - 0s 141us/step - loss: 0.6694 - acc: 0.6709 - val_loss: 2.0050 - val_acc: 0.5535\n",
      "Epoch 628/1000\n",
      "474/474 [==============================] - 0s 134us/step - loss: 0.6611 - acc: 0.6519 - val_loss: 2.0256 - val_acc: 0.5031\n",
      "Epoch 629/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.6441 - acc: 0.6772 - val_loss: 2.0615 - val_acc: 0.5157\n",
      "Epoch 630/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6363 - acc: 0.6899 - val_loss: 2.0504 - val_acc: 0.5346\n",
      "Epoch 631/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.6426 - acc: 0.6730 - val_loss: 2.0136 - val_acc: 0.5283\n",
      "Epoch 632/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.6627 - acc: 0.6561 - val_loss: 2.0455 - val_acc: 0.5346\n",
      "Epoch 633/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6421 - acc: 0.6603 - val_loss: 1.9743 - val_acc: 0.5660\n",
      "Epoch 634/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 0.6550 - acc: 0.6857 - val_loss: 2.0297 - val_acc: 0.4780\n",
      "Epoch 635/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 0.6565 - acc: 0.6540 - val_loss: 2.0767 - val_acc: 0.4969\n",
      "Epoch 636/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 0.6511 - acc: 0.6667 - val_loss: 2.0517 - val_acc: 0.5157\n",
      "Epoch 637/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6419 - acc: 0.6646 - val_loss: 2.0432 - val_acc: 0.5157\n",
      "Epoch 638/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6410 - acc: 0.6857 - val_loss: 2.0450 - val_acc: 0.5157\n",
      "Epoch 639/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6712 - acc: 0.6793 - val_loss: 2.0298 - val_acc: 0.5535\n",
      "Epoch 640/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.6464 - acc: 0.6835 - val_loss: 2.0277 - val_acc: 0.5409\n",
      "Epoch 641/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6515 - acc: 0.6603 - val_loss: 2.0477 - val_acc: 0.4906\n",
      "Epoch 642/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6468 - acc: 0.6667 - val_loss: 2.0591 - val_acc: 0.5283\n",
      "Epoch 643/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.6313 - acc: 0.6688 - val_loss: 1.9854 - val_acc: 0.5535\n",
      "Epoch 644/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6194 - acc: 0.6878 - val_loss: 2.0516 - val_acc: 0.4906\n",
      "Epoch 645/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6089 - acc: 0.6730 - val_loss: 2.0425 - val_acc: 0.5660\n",
      "Epoch 646/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.6261 - acc: 0.6878 - val_loss: 2.0264 - val_acc: 0.5031\n",
      "Epoch 647/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.6276 - acc: 0.6688 - val_loss: 2.0632 - val_acc: 0.5535\n",
      "Epoch 648/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.6456 - acc: 0.6751 - val_loss: 2.0683 - val_acc: 0.4780\n",
      "Epoch 649/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6314 - acc: 0.6624 - val_loss: 2.0222 - val_acc: 0.5409\n",
      "Epoch 650/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6598 - acc: 0.6688 - val_loss: 2.0317 - val_acc: 0.5535\n",
      "Epoch 651/1000\n",
      "474/474 [==============================] - 0s 151us/step - loss: 0.6370 - acc: 0.6878 - val_loss: 1.9677 - val_acc: 0.6038\n",
      "Epoch 652/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.6517 - acc: 0.6667 - val_loss: 2.1049 - val_acc: 0.4780\n",
      "Epoch 653/1000\n",
      "474/474 [==============================] - 0s 153us/step - loss: 0.6567 - acc: 0.6582 - val_loss: 2.0610 - val_acc: 0.5786\n",
      "Epoch 654/1000\n",
      "474/474 [==============================] - 0s 152us/step - loss: 0.6556 - acc: 0.6730 - val_loss: 2.0337 - val_acc: 0.4969\n",
      "Epoch 655/1000\n",
      "474/474 [==============================] - 0s 138us/step - loss: 0.6211 - acc: 0.6814 - val_loss: 2.0240 - val_acc: 0.5283\n",
      "Epoch 656/1000\n",
      "474/474 [==============================] - 0s 135us/step - loss: 0.6351 - acc: 0.6920 - val_loss: 2.0632 - val_acc: 0.5283\n",
      "Epoch 657/1000\n",
      "474/474 [==============================] - 0s 140us/step - loss: 0.6550 - acc: 0.6688 - val_loss: 2.0791 - val_acc: 0.5975\n",
      "Epoch 658/1000\n",
      "474/474 [==============================] - 0s 140us/step - loss: 0.6791 - acc: 0.6646 - val_loss: 2.0982 - val_acc: 0.5157\n",
      "Epoch 659/1000\n",
      "474/474 [==============================] - 0s 134us/step - loss: 0.6660 - acc: 0.6772 - val_loss: 2.0813 - val_acc: 0.5094\n",
      "Epoch 660/1000\n",
      "474/474 [==============================] - 0s 143us/step - loss: 0.6579 - acc: 0.6751 - val_loss: 2.0118 - val_acc: 0.5597\n",
      "Epoch 661/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 0.6724 - acc: 0.6392 - val_loss: 2.0870 - val_acc: 0.5094\n",
      "Epoch 662/1000\n",
      "474/474 [==============================] - 0s 138us/step - loss: 0.6226 - acc: 0.6941 - val_loss: 2.0059 - val_acc: 0.5346\n",
      "Epoch 663/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.6096 - acc: 0.6835 - val_loss: 2.0428 - val_acc: 0.5597\n",
      "Epoch 664/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6507 - acc: 0.6751 - val_loss: 2.0501 - val_acc: 0.4969\n",
      "Epoch 665/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6387 - acc: 0.6624 - val_loss: 1.9632 - val_acc: 0.5849\n",
      "Epoch 666/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.6368 - acc: 0.6646 - val_loss: 2.0171 - val_acc: 0.5409\n",
      "Epoch 667/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.6172 - acc: 0.6688 - val_loss: 2.0299 - val_acc: 0.5157\n",
      "Epoch 668/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.6279 - acc: 0.7025 - val_loss: 2.0462 - val_acc: 0.5157\n",
      "Epoch 669/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.6524 - acc: 0.6392 - val_loss: 2.0602 - val_acc: 0.5157\n",
      "Epoch 670/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.6517 - acc: 0.6835 - val_loss: 2.0752 - val_acc: 0.5220\n",
      "Epoch 671/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6440 - acc: 0.6835 - val_loss: 2.1289 - val_acc: 0.5472\n",
      "Epoch 672/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 0.6439 - acc: 0.6709 - val_loss: 2.0059 - val_acc: 0.5786\n",
      "Epoch 673/1000\n",
      "474/474 [==============================] - 0s 134us/step - loss: 0.6325 - acc: 0.6751 - val_loss: 2.0510 - val_acc: 0.5409\n",
      "Epoch 674/1000\n",
      "474/474 [==============================] - 0s 133us/step - loss: 0.6592 - acc: 0.6603 - val_loss: 2.0444 - val_acc: 0.5220\n",
      "Epoch 675/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.6618 - acc: 0.6477 - val_loss: 2.0023 - val_acc: 0.5786\n",
      "Epoch 676/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 0.6464 - acc: 0.6646 - val_loss: 2.1019 - val_acc: 0.4654\n",
      "Epoch 677/1000\n",
      "474/474 [==============================] - 0s 140us/step - loss: 0.6731 - acc: 0.6519 - val_loss: 1.9931 - val_acc: 0.5472\n",
      "Epoch 678/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 0.6348 - acc: 0.6814 - val_loss: 2.1035 - val_acc: 0.5157\n",
      "Epoch 679/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.6763 - acc: 0.6688 - val_loss: 2.0370 - val_acc: 0.5283\n",
      "Epoch 680/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 0.6365 - acc: 0.6646 - val_loss: 2.0594 - val_acc: 0.5472\n",
      "Epoch 681/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 0.6220 - acc: 0.6920 - val_loss: 2.0453 - val_acc: 0.5094\n",
      "Epoch 682/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 0.6478 - acc: 0.6435 - val_loss: 2.0629 - val_acc: 0.5031\n",
      "Epoch 683/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6529 - acc: 0.6603 - val_loss: 2.0251 - val_acc: 0.4969\n",
      "Epoch 684/1000\n",
      "474/474 [==============================] - 0s 136us/step - loss: 0.6388 - acc: 0.6688 - val_loss: 2.1053 - val_acc: 0.4717\n",
      "Epoch 685/1000\n",
      "474/474 [==============================] - 0s 134us/step - loss: 0.6699 - acc: 0.6498 - val_loss: 2.1149 - val_acc: 0.4843\n",
      "Epoch 686/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 0.6748 - acc: 0.6624 - val_loss: 1.9935 - val_acc: 0.5660\n",
      "Epoch 687/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.6345 - acc: 0.6688 - val_loss: 2.0504 - val_acc: 0.5220\n",
      "Epoch 688/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.6049 - acc: 0.6814 - val_loss: 2.0595 - val_acc: 0.4906\n",
      "Epoch 689/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 0.6098 - acc: 0.6793 - val_loss: 2.0391 - val_acc: 0.5094\n",
      "Epoch 690/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6125 - acc: 0.6582 - val_loss: 2.0493 - val_acc: 0.4843\n",
      "Epoch 691/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 0.6378 - acc: 0.6688 - val_loss: 2.0354 - val_acc: 0.5660\n",
      "Epoch 692/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6393 - acc: 0.6772 - val_loss: 2.0486 - val_acc: 0.5597\n",
      "Epoch 693/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.6744 - acc: 0.6561 - val_loss: 2.1542 - val_acc: 0.4654\n",
      "Epoch 694/1000\n",
      "474/474 [==============================] - 0s 138us/step - loss: 0.6460 - acc: 0.6688 - val_loss: 2.0664 - val_acc: 0.5409\n",
      "Epoch 695/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.6299 - acc: 0.6730 - val_loss: 2.0756 - val_acc: 0.5597\n",
      "Epoch 696/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.6354 - acc: 0.6814 - val_loss: 2.0890 - val_acc: 0.4780\n",
      "Epoch 697/1000\n",
      "474/474 [==============================] - 0s 134us/step - loss: 0.6328 - acc: 0.6603 - val_loss: 2.0589 - val_acc: 0.5472\n",
      "Epoch 698/1000\n",
      "474/474 [==============================] - 0s 139us/step - loss: 0.6506 - acc: 0.6709 - val_loss: 2.1818 - val_acc: 0.5094\n",
      "Epoch 699/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.6791 - acc: 0.6582 - val_loss: 2.0632 - val_acc: 0.5409\n",
      "Epoch 700/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6599 - acc: 0.6392 - val_loss: 2.0402 - val_acc: 0.5094\n",
      "Epoch 701/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 0.6395 - acc: 0.6772 - val_loss: 2.0432 - val_acc: 0.5409\n",
      "Epoch 702/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.6434 - acc: 0.6667 - val_loss: 2.1352 - val_acc: 0.5409\n",
      "Epoch 703/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 0.6330 - acc: 0.6603 - val_loss: 2.0207 - val_acc: 0.5723\n",
      "Epoch 704/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6309 - acc: 0.6793 - val_loss: 2.0404 - val_acc: 0.5283\n",
      "Epoch 705/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6389 - acc: 0.6667 - val_loss: 2.0805 - val_acc: 0.4969\n",
      "Epoch 706/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.6202 - acc: 0.6582 - val_loss: 2.0091 - val_acc: 0.5535\n",
      "Epoch 707/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.6045 - acc: 0.6793 - val_loss: 2.0737 - val_acc: 0.5409\n",
      "Epoch 708/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.6082 - acc: 0.6751 - val_loss: 2.0325 - val_acc: 0.5660\n",
      "Epoch 709/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6141 - acc: 0.6667 - val_loss: 2.0844 - val_acc: 0.4843\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/474 [==============================] - 0s 124us/step - loss: 0.6264 - acc: 0.6751 - val_loss: 2.0259 - val_acc: 0.5283\n",
      "Epoch 711/1000\n",
      "474/474 [==============================] - 0s 135us/step - loss: 0.6198 - acc: 0.6709 - val_loss: 2.0199 - val_acc: 0.5472\n",
      "Epoch 712/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.6160 - acc: 0.6730 - val_loss: 2.0656 - val_acc: 0.5031\n",
      "Epoch 713/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6252 - acc: 0.6772 - val_loss: 2.0507 - val_acc: 0.5094\n",
      "Epoch 714/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6466 - acc: 0.6308 - val_loss: 2.1284 - val_acc: 0.4465\n",
      "Epoch 715/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6111 - acc: 0.6814 - val_loss: 2.0565 - val_acc: 0.5346\n",
      "Epoch 716/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.6271 - acc: 0.6730 - val_loss: 2.0320 - val_acc: 0.5535\n",
      "Epoch 717/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6225 - acc: 0.6878 - val_loss: 2.1255 - val_acc: 0.5346\n",
      "Epoch 718/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 0.6677 - acc: 0.6646 - val_loss: 2.0521 - val_acc: 0.5409\n",
      "Epoch 719/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.6396 - acc: 0.6646 - val_loss: 2.0139 - val_acc: 0.5283\n",
      "Epoch 720/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.6489 - acc: 0.6603 - val_loss: 2.0317 - val_acc: 0.4969\n",
      "Epoch 721/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6177 - acc: 0.6835 - val_loss: 2.0215 - val_acc: 0.5031\n",
      "Epoch 722/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.5994 - acc: 0.6793 - val_loss: 2.0448 - val_acc: 0.5409\n",
      "Epoch 723/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6250 - acc: 0.6688 - val_loss: 2.0251 - val_acc: 0.5472\n",
      "Epoch 724/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6123 - acc: 0.6814 - val_loss: 2.0499 - val_acc: 0.5031\n",
      "Epoch 725/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6298 - acc: 0.6730 - val_loss: 2.0372 - val_acc: 0.5031\n",
      "Epoch 726/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 0.6137 - acc: 0.6920 - val_loss: 2.0708 - val_acc: 0.5031\n",
      "Epoch 727/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6214 - acc: 0.6793 - val_loss: 2.0185 - val_acc: 0.5723\n",
      "Epoch 728/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6420 - acc: 0.6751 - val_loss: 2.0058 - val_acc: 0.5472\n",
      "Epoch 729/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6301 - acc: 0.6878 - val_loss: 2.0562 - val_acc: 0.5660\n",
      "Epoch 730/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.6171 - acc: 0.6814 - val_loss: 2.0653 - val_acc: 0.5409\n",
      "Epoch 731/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.6286 - acc: 0.6878 - val_loss: 2.0607 - val_acc: 0.5786\n",
      "Epoch 732/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6370 - acc: 0.6709 - val_loss: 2.0297 - val_acc: 0.5094\n",
      "Epoch 733/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 0.6232 - acc: 0.6709 - val_loss: 2.0688 - val_acc: 0.5220\n",
      "Epoch 734/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.6245 - acc: 0.6772 - val_loss: 2.0501 - val_acc: 0.5472\n",
      "Epoch 735/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6048 - acc: 0.6814 - val_loss: 2.0353 - val_acc: 0.5409\n",
      "Epoch 736/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.6157 - acc: 0.6772 - val_loss: 2.0670 - val_acc: 0.5535\n",
      "Epoch 737/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.6090 - acc: 0.6793 - val_loss: 2.0364 - val_acc: 0.5283\n",
      "Epoch 738/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.6072 - acc: 0.6835 - val_loss: 2.0506 - val_acc: 0.5535\n",
      "Epoch 739/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.6329 - acc: 0.6962 - val_loss: 2.0775 - val_acc: 0.5157\n",
      "Epoch 740/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 0.6442 - acc: 0.6688 - val_loss: 2.0712 - val_acc: 0.5031\n",
      "Epoch 741/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6345 - acc: 0.6793 - val_loss: 2.0643 - val_acc: 0.5283\n",
      "Epoch 742/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.6481 - acc: 0.6561 - val_loss: 2.0584 - val_acc: 0.5094\n",
      "Epoch 743/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6617 - acc: 0.6540 - val_loss: 2.0106 - val_acc: 0.5723\n",
      "Epoch 744/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.6082 - acc: 0.6772 - val_loss: 2.0624 - val_acc: 0.5220\n",
      "Epoch 745/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.6336 - acc: 0.6646 - val_loss: 2.0648 - val_acc: 0.5346\n",
      "Epoch 746/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6283 - acc: 0.6709 - val_loss: 2.1096 - val_acc: 0.4780\n",
      "Epoch 747/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6376 - acc: 0.6456 - val_loss: 2.0303 - val_acc: 0.5094\n",
      "Epoch 748/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.6047 - acc: 0.6688 - val_loss: 2.0888 - val_acc: 0.5346\n",
      "Epoch 749/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.6311 - acc: 0.6646 - val_loss: 2.0447 - val_acc: 0.4843\n",
      "Epoch 750/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.6278 - acc: 0.6920 - val_loss: 2.0101 - val_acc: 0.5094\n",
      "Epoch 751/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6260 - acc: 0.6983 - val_loss: 2.0859 - val_acc: 0.5472\n",
      "Epoch 752/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6405 - acc: 0.6646 - val_loss: 2.0634 - val_acc: 0.4843\n",
      "Epoch 753/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6142 - acc: 0.6624 - val_loss: 2.0442 - val_acc: 0.5472\n",
      "Epoch 754/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6310 - acc: 0.6730 - val_loss: 2.0785 - val_acc: 0.5409\n",
      "Epoch 755/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6142 - acc: 0.6983 - val_loss: 2.0074 - val_acc: 0.5220\n",
      "Epoch 756/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6219 - acc: 0.6688 - val_loss: 2.0313 - val_acc: 0.5409\n",
      "Epoch 757/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6049 - acc: 0.6730 - val_loss: 2.0586 - val_acc: 0.5346\n",
      "Epoch 758/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6397 - acc: 0.6688 - val_loss: 2.0451 - val_acc: 0.5094\n",
      "Epoch 759/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6404 - acc: 0.6667 - val_loss: 2.0704 - val_acc: 0.5346\n",
      "Epoch 760/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6213 - acc: 0.6751 - val_loss: 2.0853 - val_acc: 0.5346\n",
      "Epoch 761/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6377 - acc: 0.6793 - val_loss: 2.0294 - val_acc: 0.5597\n",
      "Epoch 762/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.6323 - acc: 0.6603 - val_loss: 2.0533 - val_acc: 0.5660\n",
      "Epoch 763/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.5981 - acc: 0.7110 - val_loss: 2.0595 - val_acc: 0.5472\n",
      "Epoch 764/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6158 - acc: 0.6730 - val_loss: 2.0492 - val_acc: 0.5283\n",
      "Epoch 765/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6349 - acc: 0.6540 - val_loss: 2.0637 - val_acc: 0.5346\n",
      "Epoch 766/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6526 - acc: 0.6477 - val_loss: 2.1014 - val_acc: 0.5220\n",
      "Epoch 767/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 0.6272 - acc: 0.6772 - val_loss: 2.0930 - val_acc: 0.5157\n",
      "Epoch 768/1000\n",
      "474/474 [==============================] - 0s 134us/step - loss: 0.6207 - acc: 0.6878 - val_loss: 2.0372 - val_acc: 0.5346\n",
      "Epoch 769/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6252 - acc: 0.6899 - val_loss: 2.0971 - val_acc: 0.5535\n",
      "Epoch 770/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.6383 - acc: 0.6624 - val_loss: 2.1089 - val_acc: 0.4717\n",
      "Epoch 771/1000\n",
      "474/474 [==============================] - 0s 144us/step - loss: 0.6216 - acc: 0.6519 - val_loss: 2.0932 - val_acc: 0.5283\n",
      "Epoch 772/1000\n",
      "474/474 [==============================] - 0s 134us/step - loss: 0.6231 - acc: 0.6751 - val_loss: 2.0327 - val_acc: 0.5597\n",
      "Epoch 773/1000\n",
      "474/474 [==============================] - 0s 146us/step - loss: 0.6120 - acc: 0.6857 - val_loss: 2.1313 - val_acc: 0.5031\n",
      "Epoch 774/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.6268 - acc: 0.6793 - val_loss: 1.9863 - val_acc: 0.5597\n",
      "Epoch 775/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.6465 - acc: 0.6561 - val_loss: 2.0611 - val_acc: 0.4906\n",
      "Epoch 776/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6462 - acc: 0.6688 - val_loss: 2.1273 - val_acc: 0.4843\n",
      "Epoch 777/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 0.6268 - acc: 0.6899 - val_loss: 2.1125 - val_acc: 0.5409\n",
      "Epoch 778/1000\n",
      "474/474 [==============================] - 0s 134us/step - loss: 0.6504 - acc: 0.6540 - val_loss: 2.0714 - val_acc: 0.4780\n",
      "Epoch 779/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6022 - acc: 0.6814 - val_loss: 2.0116 - val_acc: 0.5409\n",
      "Epoch 780/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.5985 - acc: 0.6814 - val_loss: 2.0574 - val_acc: 0.5031\n",
      "Epoch 781/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.5930 - acc: 0.6835 - val_loss: 2.0463 - val_acc: 0.5220\n",
      "Epoch 782/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6082 - acc: 0.6646 - val_loss: 2.0904 - val_acc: 0.4969\n",
      "Epoch 783/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6043 - acc: 0.6709 - val_loss: 2.0784 - val_acc: 0.4906\n",
      "Epoch 784/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.6261 - acc: 0.6582 - val_loss: 2.0845 - val_acc: 0.5094\n",
      "Epoch 785/1000\n",
      "474/474 [==============================] - 0s 136us/step - loss: 0.6112 - acc: 0.6709 - val_loss: 2.0441 - val_acc: 0.5283\n",
      "Epoch 786/1000\n",
      "474/474 [==============================] - 0s 135us/step - loss: 0.6071 - acc: 0.6730 - val_loss: 2.0417 - val_acc: 0.5283\n",
      "Epoch 787/1000\n",
      "474/474 [==============================] - 0s 156us/step - loss: 0.6268 - acc: 0.6878 - val_loss: 2.0758 - val_acc: 0.5346\n",
      "Epoch 788/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 0.6244 - acc: 0.6624 - val_loss: 2.0826 - val_acc: 0.5472\n",
      "Epoch 789/1000\n",
      "474/474 [==============================] - 0s 133us/step - loss: 0.6305 - acc: 0.6582 - val_loss: 2.1128 - val_acc: 0.5031\n",
      "Epoch 790/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6325 - acc: 0.6899 - val_loss: 2.0537 - val_acc: 0.5409\n",
      "Epoch 791/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6349 - acc: 0.6456 - val_loss: 2.0228 - val_acc: 0.5535\n",
      "Epoch 792/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 0.6277 - acc: 0.6793 - val_loss: 2.0740 - val_acc: 0.5157\n",
      "Epoch 793/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.5964 - acc: 0.6899 - val_loss: 2.1124 - val_acc: 0.5409\n",
      "Epoch 794/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6110 - acc: 0.6793 - val_loss: 2.0495 - val_acc: 0.5157\n",
      "Epoch 795/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 0.6306 - acc: 0.6603 - val_loss: 2.0709 - val_acc: 0.4969\n",
      "Epoch 796/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 0.6043 - acc: 0.6772 - val_loss: 2.0356 - val_acc: 0.5472\n",
      "Epoch 797/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.6127 - acc: 0.6730 - val_loss: 2.0648 - val_acc: 0.5660\n",
      "Epoch 798/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 0.6048 - acc: 0.6772 - val_loss: 2.0588 - val_acc: 0.5283\n",
      "Epoch 799/1000\n",
      "474/474 [==============================] - 0s 137us/step - loss: 0.6007 - acc: 0.6878 - val_loss: 2.0779 - val_acc: 0.4906\n",
      "Epoch 800/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6081 - acc: 0.6920 - val_loss: 2.0662 - val_acc: 0.5094\n",
      "Epoch 801/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6488 - acc: 0.6350 - val_loss: 2.0784 - val_acc: 0.5283\n",
      "Epoch 802/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.6291 - acc: 0.6962 - val_loss: 2.1114 - val_acc: 0.5786\n",
      "Epoch 803/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6093 - acc: 0.6835 - val_loss: 2.0753 - val_acc: 0.5472\n",
      "Epoch 804/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6186 - acc: 0.6857 - val_loss: 2.1890 - val_acc: 0.4528\n",
      "Epoch 805/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 0.6331 - acc: 0.6730 - val_loss: 2.0998 - val_acc: 0.5346\n",
      "Epoch 806/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.6230 - acc: 0.6793 - val_loss: 2.0455 - val_acc: 0.5094\n",
      "Epoch 807/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.5977 - acc: 0.6878 - val_loss: 2.0764 - val_acc: 0.4843\n",
      "Epoch 808/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6033 - acc: 0.6835 - val_loss: 2.0734 - val_acc: 0.5409\n",
      "Epoch 809/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6168 - acc: 0.6624 - val_loss: 2.0785 - val_acc: 0.5283\n",
      "Epoch 810/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6129 - acc: 0.6878 - val_loss: 2.0697 - val_acc: 0.5409\n",
      "Epoch 811/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6035 - acc: 0.6835 - val_loss: 2.0733 - val_acc: 0.5723\n",
      "Epoch 812/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6170 - acc: 0.6730 - val_loss: 2.0873 - val_acc: 0.5597\n",
      "Epoch 813/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.5970 - acc: 0.6835 - val_loss: 2.0828 - val_acc: 0.5220\n",
      "Epoch 814/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6031 - acc: 0.6920 - val_loss: 2.0234 - val_acc: 0.5535\n",
      "Epoch 815/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6028 - acc: 0.6793 - val_loss: 2.1309 - val_acc: 0.5283\n",
      "Epoch 816/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.5915 - acc: 0.6878 - val_loss: 2.0580 - val_acc: 0.5535\n",
      "Epoch 817/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6190 - acc: 0.6730 - val_loss: 2.0792 - val_acc: 0.4780\n",
      "Epoch 818/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.5995 - acc: 0.6941 - val_loss: 2.1047 - val_acc: 0.4843\n",
      "Epoch 819/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6054 - acc: 0.6498 - val_loss: 2.0947 - val_acc: 0.5535\n",
      "Epoch 820/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.6014 - acc: 0.6582 - val_loss: 2.0781 - val_acc: 0.4906\n",
      "Epoch 821/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.6069 - acc: 0.6624 - val_loss: 2.0486 - val_acc: 0.5535\n",
      "Epoch 822/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.6085 - acc: 0.6941 - val_loss: 2.0717 - val_acc: 0.5535\n",
      "Epoch 823/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.6119 - acc: 0.6772 - val_loss: 2.0926 - val_acc: 0.5409\n",
      "Epoch 824/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.5936 - acc: 0.6730 - val_loss: 2.0454 - val_acc: 0.5535\n",
      "Epoch 825/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6027 - acc: 0.6835 - val_loss: 2.0860 - val_acc: 0.5849\n",
      "Epoch 826/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6085 - acc: 0.6730 - val_loss: 2.1036 - val_acc: 0.5094\n",
      "Epoch 827/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6033 - acc: 0.6772 - val_loss: 2.1218 - val_acc: 0.5094\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/474 [==============================] - 0s 103us/step - loss: 0.5966 - acc: 0.6793 - val_loss: 2.1063 - val_acc: 0.5094\n",
      "Epoch 829/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6095 - acc: 0.7046 - val_loss: 2.1261 - val_acc: 0.5157\n",
      "Epoch 830/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6094 - acc: 0.6793 - val_loss: 2.0857 - val_acc: 0.5094\n",
      "Epoch 831/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.5921 - acc: 0.6857 - val_loss: 2.1013 - val_acc: 0.4969\n",
      "Epoch 832/1000\n",
      "474/474 [==============================] - 0s 101us/step - loss: 0.6217 - acc: 0.6709 - val_loss: 2.0529 - val_acc: 0.5094\n",
      "Epoch 833/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.5928 - acc: 0.6540 - val_loss: 2.0863 - val_acc: 0.5409\n",
      "Epoch 834/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.5911 - acc: 0.6814 - val_loss: 2.1029 - val_acc: 0.4654\n",
      "Epoch 835/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.5878 - acc: 0.6857 - val_loss: 2.0957 - val_acc: 0.5283\n",
      "Epoch 836/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.6056 - acc: 0.6730 - val_loss: 2.0508 - val_acc: 0.5660\n",
      "Epoch 837/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 0.6108 - acc: 0.6899 - val_loss: 2.1368 - val_acc: 0.4843\n",
      "Epoch 838/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 0.6134 - acc: 0.6920 - val_loss: 2.0792 - val_acc: 0.5283\n",
      "Epoch 839/1000\n",
      "474/474 [==============================] - 0s 139us/step - loss: 0.6341 - acc: 0.6688 - val_loss: 2.1423 - val_acc: 0.4969\n",
      "Epoch 840/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.6327 - acc: 0.6540 - val_loss: 2.1242 - val_acc: 0.5094\n",
      "Epoch 841/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 0.6642 - acc: 0.6624 - val_loss: 2.1094 - val_acc: 0.5157\n",
      "Epoch 842/1000\n",
      "474/474 [==============================] - 0s 149us/step - loss: 0.6614 - acc: 0.6582 - val_loss: 2.0742 - val_acc: 0.5283\n",
      "Epoch 843/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 0.6275 - acc: 0.6751 - val_loss: 2.0485 - val_acc: 0.4717\n",
      "Epoch 844/1000\n",
      "474/474 [==============================] - 0s 134us/step - loss: 0.6494 - acc: 0.6624 - val_loss: 2.0687 - val_acc: 0.5283\n",
      "Epoch 845/1000\n",
      "474/474 [==============================] - 0s 162us/step - loss: 0.6426 - acc: 0.6498 - val_loss: 2.0418 - val_acc: 0.5912\n",
      "Epoch 846/1000\n",
      "474/474 [==============================] - 0s 152us/step - loss: 0.6313 - acc: 0.6688 - val_loss: 2.1626 - val_acc: 0.4717\n",
      "Epoch 847/1000\n",
      "474/474 [==============================] - 0s 159us/step - loss: 0.6033 - acc: 0.6709 - val_loss: 2.0537 - val_acc: 0.5409\n",
      "Epoch 848/1000\n",
      "474/474 [==============================] - 0s 132us/step - loss: 0.6096 - acc: 0.6477 - val_loss: 2.0940 - val_acc: 0.5220\n",
      "Epoch 849/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6013 - acc: 0.6730 - val_loss: 2.0727 - val_acc: 0.5157\n",
      "Epoch 850/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 0.5991 - acc: 0.6941 - val_loss: 2.0865 - val_acc: 0.5283\n",
      "Epoch 851/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.5924 - acc: 0.6814 - val_loss: 2.0571 - val_acc: 0.5409\n",
      "Epoch 852/1000\n",
      "474/474 [==============================] - 0s 137us/step - loss: 0.5919 - acc: 0.6835 - val_loss: 2.0961 - val_acc: 0.5597\n",
      "Epoch 853/1000\n",
      "474/474 [==============================] - 0s 147us/step - loss: 0.6159 - acc: 0.6603 - val_loss: 2.1573 - val_acc: 0.4780\n",
      "Epoch 854/1000\n",
      "474/474 [==============================] - 0s 157us/step - loss: 0.6216 - acc: 0.6646 - val_loss: 2.1284 - val_acc: 0.5094\n",
      "Epoch 855/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 0.6354 - acc: 0.6603 - val_loss: 2.0653 - val_acc: 0.5723\n",
      "Epoch 856/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.6207 - acc: 0.6624 - val_loss: 2.0806 - val_acc: 0.5220\n",
      "Epoch 857/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6008 - acc: 0.6835 - val_loss: 2.0755 - val_acc: 0.5283\n",
      "Epoch 858/1000\n",
      "474/474 [==============================] - 0s 130us/step - loss: 0.5988 - acc: 0.6688 - val_loss: 2.0866 - val_acc: 0.5597\n",
      "Epoch 859/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6029 - acc: 0.6751 - val_loss: 2.1103 - val_acc: 0.5094\n",
      "Epoch 860/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.6210 - acc: 0.6624 - val_loss: 2.0895 - val_acc: 0.5157\n",
      "Epoch 861/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.6687 - acc: 0.6392 - val_loss: 2.1792 - val_acc: 0.5220\n",
      "Epoch 862/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.6363 - acc: 0.6667 - val_loss: 2.0742 - val_acc: 0.5346\n",
      "Epoch 863/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 0.6078 - acc: 0.6624 - val_loss: 2.1282 - val_acc: 0.5346\n",
      "Epoch 864/1000\n",
      "474/474 [==============================] - 0s 135us/step - loss: 0.6096 - acc: 0.6793 - val_loss: 2.0697 - val_acc: 0.5157\n",
      "Epoch 865/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.5990 - acc: 0.6667 - val_loss: 2.0678 - val_acc: 0.5849\n",
      "Epoch 866/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.5766 - acc: 0.7068 - val_loss: 2.1208 - val_acc: 0.5346\n",
      "Epoch 867/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.6119 - acc: 0.6835 - val_loss: 2.1292 - val_acc: 0.4843\n",
      "Epoch 868/1000\n",
      "474/474 [==============================] - 0s 118us/step - loss: 0.6049 - acc: 0.6603 - val_loss: 2.0785 - val_acc: 0.5220\n",
      "Epoch 869/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.5950 - acc: 0.6857 - val_loss: 2.0615 - val_acc: 0.5597\n",
      "Epoch 870/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.6024 - acc: 0.6603 - val_loss: 2.0822 - val_acc: 0.4969\n",
      "Epoch 871/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 0.6101 - acc: 0.6772 - val_loss: 2.0613 - val_acc: 0.4906\n",
      "Epoch 872/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.5967 - acc: 0.6857 - val_loss: 2.0745 - val_acc: 0.5220\n",
      "Epoch 873/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.6162 - acc: 0.6688 - val_loss: 2.1298 - val_acc: 0.4780\n",
      "Epoch 874/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.5878 - acc: 0.6878 - val_loss: 2.0784 - val_acc: 0.5535\n",
      "Epoch 875/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.5983 - acc: 0.6751 - val_loss: 2.1149 - val_acc: 0.5346\n",
      "Epoch 876/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.5946 - acc: 0.6688 - val_loss: 2.1567 - val_acc: 0.4403\n",
      "Epoch 877/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6080 - acc: 0.6857 - val_loss: 2.0666 - val_acc: 0.5535\n",
      "Epoch 878/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 0.6001 - acc: 0.6793 - val_loss: 2.0820 - val_acc: 0.5346\n",
      "Epoch 879/1000\n",
      "474/474 [==============================] - 0s 135us/step - loss: 0.6043 - acc: 0.6962 - val_loss: 2.0682 - val_acc: 0.5472\n",
      "Epoch 880/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.5886 - acc: 0.6899 - val_loss: 2.1160 - val_acc: 0.5283\n",
      "Epoch 881/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.6273 - acc: 0.6624 - val_loss: 2.1181 - val_acc: 0.5220\n",
      "Epoch 882/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.6151 - acc: 0.6646 - val_loss: 2.1108 - val_acc: 0.5031\n",
      "Epoch 883/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.5855 - acc: 0.6878 - val_loss: 2.0824 - val_acc: 0.5409\n",
      "Epoch 884/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.6249 - acc: 0.6688 - val_loss: 2.1361 - val_acc: 0.5409\n",
      "Epoch 885/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.5792 - acc: 0.7110 - val_loss: 2.0869 - val_acc: 0.5031\n",
      "Epoch 886/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.6055 - acc: 0.6709 - val_loss: 2.1041 - val_acc: 0.5220\n",
      "Epoch 887/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.5849 - acc: 0.7025 - val_loss: 2.1084 - val_acc: 0.5157\n",
      "Epoch 888/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.5784 - acc: 0.6793 - val_loss: 2.1431 - val_acc: 0.5597\n",
      "Epoch 889/1000\n",
      "474/474 [==============================] - 0s 125us/step - loss: 0.5821 - acc: 0.6793 - val_loss: 2.1542 - val_acc: 0.4654\n",
      "Epoch 890/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.5820 - acc: 0.7025 - val_loss: 2.1419 - val_acc: 0.4906\n",
      "Epoch 891/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.5651 - acc: 0.7004 - val_loss: 2.0744 - val_acc: 0.5660\n",
      "Epoch 892/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.5931 - acc: 0.6772 - val_loss: 2.1022 - val_acc: 0.5535\n",
      "Epoch 893/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.5957 - acc: 0.6878 - val_loss: 2.0832 - val_acc: 0.5535\n",
      "Epoch 894/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 0.6080 - acc: 0.6772 - val_loss: 2.1555 - val_acc: 0.5094\n",
      "Epoch 895/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.5924 - acc: 0.6835 - val_loss: 2.0697 - val_acc: 0.4906\n",
      "Epoch 896/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.5983 - acc: 0.6730 - val_loss: 2.0700 - val_acc: 0.5535\n",
      "Epoch 897/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.6048 - acc: 0.7046 - val_loss: 2.0759 - val_acc: 0.5346\n",
      "Epoch 898/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.5921 - acc: 0.6751 - val_loss: 2.1389 - val_acc: 0.4969\n",
      "Epoch 899/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.6105 - acc: 0.6667 - val_loss: 2.1033 - val_acc: 0.5409\n",
      "Epoch 900/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.6223 - acc: 0.6603 - val_loss: 2.0995 - val_acc: 0.5220\n",
      "Epoch 901/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.6054 - acc: 0.6667 - val_loss: 2.1016 - val_acc: 0.4906\n",
      "Epoch 902/1000\n",
      "474/474 [==============================] - 0s 119us/step - loss: 0.5862 - acc: 0.6814 - val_loss: 2.0553 - val_acc: 0.5283\n",
      "Epoch 903/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.5984 - acc: 0.6688 - val_loss: 2.0692 - val_acc: 0.5220\n",
      "Epoch 904/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 0.5927 - acc: 0.6730 - val_loss: 2.0617 - val_acc: 0.5409\n",
      "Epoch 905/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.6045 - acc: 0.6709 - val_loss: 2.1276 - val_acc: 0.5409\n",
      "Epoch 906/1000\n",
      "474/474 [==============================] - 0s 116us/step - loss: 0.5915 - acc: 0.6941 - val_loss: 2.1263 - val_acc: 0.4969\n",
      "Epoch 907/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.5724 - acc: 0.7089 - val_loss: 2.1352 - val_acc: 0.4780\n",
      "Epoch 908/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.5729 - acc: 0.6983 - val_loss: 2.0995 - val_acc: 0.5220\n",
      "Epoch 909/1000\n",
      "474/474 [==============================] - 0s 128us/step - loss: 0.5851 - acc: 0.6835 - val_loss: 2.1186 - val_acc: 0.5031\n",
      "Epoch 910/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.5860 - acc: 0.6899 - val_loss: 2.0803 - val_acc: 0.5220\n",
      "Epoch 911/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6235 - acc: 0.6667 - val_loss: 2.1264 - val_acc: 0.5157\n",
      "Epoch 912/1000\n",
      "474/474 [==============================] - 0s 102us/step - loss: 0.6352 - acc: 0.6709 - val_loss: 2.0996 - val_acc: 0.5346\n",
      "Epoch 913/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6075 - acc: 0.6730 - val_loss: 2.1451 - val_acc: 0.5031\n",
      "Epoch 914/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6037 - acc: 0.6835 - val_loss: 2.1005 - val_acc: 0.5283\n",
      "Epoch 915/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6208 - acc: 0.6688 - val_loss: 2.1451 - val_acc: 0.4969\n",
      "Epoch 916/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.6021 - acc: 0.6878 - val_loss: 2.0780 - val_acc: 0.5472\n",
      "Epoch 917/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.6177 - acc: 0.6667 - val_loss: 2.1536 - val_acc: 0.5660\n",
      "Epoch 918/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.6220 - acc: 0.6878 - val_loss: 2.0597 - val_acc: 0.5660\n",
      "Epoch 919/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.5944 - acc: 0.6814 - val_loss: 2.1295 - val_acc: 0.4843\n",
      "Epoch 920/1000\n",
      "474/474 [==============================] - 0s 124us/step - loss: 0.6023 - acc: 0.6772 - val_loss: 2.0769 - val_acc: 0.5283\n",
      "Epoch 921/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.5932 - acc: 0.6751 - val_loss: 2.1147 - val_acc: 0.4969\n",
      "Epoch 922/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.5772 - acc: 0.6582 - val_loss: 2.0927 - val_acc: 0.5031\n",
      "Epoch 923/1000\n",
      "474/474 [==============================] - 0s 127us/step - loss: 0.5743 - acc: 0.6857 - val_loss: 2.0734 - val_acc: 0.5220\n",
      "Epoch 924/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.5908 - acc: 0.6983 - val_loss: 2.0606 - val_acc: 0.5409\n",
      "Epoch 925/1000\n",
      "474/474 [==============================] - 0s 126us/step - loss: 0.5992 - acc: 0.6751 - val_loss: 2.0896 - val_acc: 0.5723\n",
      "Epoch 926/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.5987 - acc: 0.6814 - val_loss: 2.0119 - val_acc: 0.5346\n",
      "Epoch 927/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.5862 - acc: 0.7004 - val_loss: 2.1767 - val_acc: 0.4843\n",
      "Epoch 928/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.6006 - acc: 0.6730 - val_loss: 2.1207 - val_acc: 0.5660\n",
      "Epoch 929/1000\n",
      "474/474 [==============================] - 0s 113us/step - loss: 0.6496 - acc: 0.6540 - val_loss: 2.1810 - val_acc: 0.4717\n",
      "Epoch 930/1000\n",
      "474/474 [==============================] - 0s 114us/step - loss: 0.6463 - acc: 0.6435 - val_loss: 2.0797 - val_acc: 0.5723\n",
      "Epoch 931/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.6101 - acc: 0.6857 - val_loss: 2.0452 - val_acc: 0.5283\n",
      "Epoch 932/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.5702 - acc: 0.6814 - val_loss: 2.0417 - val_acc: 0.5472\n",
      "Epoch 933/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.5949 - acc: 0.7046 - val_loss: 2.1238 - val_acc: 0.5094\n",
      "Epoch 934/1000\n",
      "474/474 [==============================] - 0s 122us/step - loss: 0.5761 - acc: 0.6835 - val_loss: 2.0677 - val_acc: 0.5535\n",
      "Epoch 935/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.5795 - acc: 0.6730 - val_loss: 2.1001 - val_acc: 0.5472\n",
      "Epoch 936/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.5900 - acc: 0.6857 - val_loss: 2.1265 - val_acc: 0.4906\n",
      "Epoch 937/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.6142 - acc: 0.6751 - val_loss: 2.1247 - val_acc: 0.5409\n",
      "Epoch 938/1000\n",
      "474/474 [==============================] - 0s 123us/step - loss: 0.5939 - acc: 0.6582 - val_loss: 2.1253 - val_acc: 0.5031\n",
      "Epoch 939/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 0.5891 - acc: 0.6941 - val_loss: 2.0790 - val_acc: 0.5849\n",
      "Epoch 940/1000\n",
      "474/474 [==============================] - 0s 137us/step - loss: 0.5981 - acc: 0.6730 - val_loss: 2.0585 - val_acc: 0.4780\n",
      "Epoch 941/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.6029 - acc: 0.6835 - val_loss: 2.1049 - val_acc: 0.5220\n",
      "Epoch 942/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.6212 - acc: 0.6688 - val_loss: 2.1484 - val_acc: 0.4969\n",
      "Epoch 943/1000\n",
      "474/474 [==============================] - 0s 115us/step - loss: 0.5953 - acc: 0.6772 - val_loss: 2.0719 - val_acc: 0.5220\n",
      "Epoch 944/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.5786 - acc: 0.6814 - val_loss: 2.0990 - val_acc: 0.5409\n",
      "Epoch 945/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.6023 - acc: 0.6835 - val_loss: 2.1400 - val_acc: 0.4969\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/474 [==============================] - 0s 104us/step - loss: 0.6139 - acc: 0.6456 - val_loss: 2.0241 - val_acc: 0.5472\n",
      "Epoch 947/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6382 - acc: 0.6582 - val_loss: 2.0818 - val_acc: 0.4906\n",
      "Epoch 948/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.5897 - acc: 0.6709 - val_loss: 2.1114 - val_acc: 0.4843\n",
      "Epoch 949/1000\n",
      "474/474 [==============================] - 0s 117us/step - loss: 0.5866 - acc: 0.6983 - val_loss: 2.0957 - val_acc: 0.5283\n",
      "Epoch 950/1000\n",
      "474/474 [==============================] - 0s 129us/step - loss: 0.5857 - acc: 0.6835 - val_loss: 2.1163 - val_acc: 0.5472\n",
      "Epoch 951/1000\n",
      "474/474 [==============================] - 0s 121us/step - loss: 0.5770 - acc: 0.6730 - val_loss: 2.1076 - val_acc: 0.5157\n",
      "Epoch 952/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6006 - acc: 0.6793 - val_loss: 2.1259 - val_acc: 0.5660\n",
      "Epoch 953/1000\n",
      "474/474 [==============================] - 0s 101us/step - loss: 0.5884 - acc: 0.6793 - val_loss: 2.1261 - val_acc: 0.4843\n",
      "Epoch 954/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.5842 - acc: 0.6857 - val_loss: 2.0895 - val_acc: 0.5220\n",
      "Epoch 955/1000\n",
      "474/474 [==============================] - 0s 110us/step - loss: 0.5931 - acc: 0.6814 - val_loss: 2.1567 - val_acc: 0.4969\n",
      "Epoch 956/1000\n",
      "474/474 [==============================] - 0s 131us/step - loss: 0.5919 - acc: 0.6814 - val_loss: 2.0799 - val_acc: 0.5535\n",
      "Epoch 957/1000\n",
      "474/474 [==============================] - 0s 139us/step - loss: 0.5777 - acc: 0.6941 - val_loss: 2.0939 - val_acc: 0.5094\n",
      "Epoch 958/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.5745 - acc: 0.6983 - val_loss: 2.1287 - val_acc: 0.5220\n",
      "Epoch 959/1000\n",
      "474/474 [==============================] - 0s 120us/step - loss: 0.5923 - acc: 0.6835 - val_loss: 2.1460 - val_acc: 0.5409\n",
      "Epoch 960/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.5883 - acc: 0.6878 - val_loss: 2.0613 - val_acc: 0.5346\n",
      "Epoch 961/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.5815 - acc: 0.6920 - val_loss: 2.0736 - val_acc: 0.5346\n",
      "Epoch 962/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.5779 - acc: 0.6835 - val_loss: 2.1181 - val_acc: 0.5094\n",
      "Epoch 963/1000\n",
      "474/474 [==============================] - 0s 94us/step - loss: 0.5826 - acc: 0.6899 - val_loss: 2.0729 - val_acc: 0.5472\n",
      "Epoch 964/1000\n",
      "474/474 [==============================] - 0s 96us/step - loss: 0.5809 - acc: 0.6857 - val_loss: 2.0615 - val_acc: 0.5723\n",
      "Epoch 965/1000\n",
      "474/474 [==============================] - 0s 92us/step - loss: 0.5867 - acc: 0.6835 - val_loss: 2.1168 - val_acc: 0.5094\n",
      "Epoch 966/1000\n",
      "474/474 [==============================] - 0s 95us/step - loss: 0.5887 - acc: 0.6688 - val_loss: 2.1460 - val_acc: 0.4906\n",
      "Epoch 967/1000\n",
      "474/474 [==============================] - 0s 101us/step - loss: 0.5796 - acc: 0.6835 - val_loss: 2.1566 - val_acc: 0.5535\n",
      "Epoch 968/1000\n",
      "474/474 [==============================] - 0s 96us/step - loss: 0.5937 - acc: 0.6709 - val_loss: 2.0986 - val_acc: 0.4528\n",
      "Epoch 969/1000\n",
      "474/474 [==============================] - 0s 90us/step - loss: 0.5790 - acc: 0.6730 - val_loss: 2.1377 - val_acc: 0.5346\n",
      "Epoch 970/1000\n",
      "474/474 [==============================] - 0s 90us/step - loss: 0.6146 - acc: 0.6561 - val_loss: 2.1539 - val_acc: 0.4780\n",
      "Epoch 971/1000\n",
      "474/474 [==============================] - 0s 92us/step - loss: 0.5892 - acc: 0.6835 - val_loss: 2.0734 - val_acc: 0.5660\n",
      "Epoch 972/1000\n",
      "474/474 [==============================] - 0s 93us/step - loss: 0.5891 - acc: 0.6709 - val_loss: 2.1236 - val_acc: 0.4780\n",
      "Epoch 973/1000\n",
      "474/474 [==============================] - 0s 89us/step - loss: 0.5734 - acc: 0.6899 - val_loss: 2.0604 - val_acc: 0.5409\n",
      "Epoch 974/1000\n",
      "474/474 [==============================] - 0s 91us/step - loss: 0.6096 - acc: 0.6582 - val_loss: 2.0929 - val_acc: 0.5912\n",
      "Epoch 975/1000\n",
      "474/474 [==============================] - 0s 92us/step - loss: 0.6029 - acc: 0.6751 - val_loss: 2.2139 - val_acc: 0.4780\n",
      "Epoch 976/1000\n",
      "474/474 [==============================] - 0s 98us/step - loss: 0.5816 - acc: 0.6793 - val_loss: 2.1250 - val_acc: 0.4843\n",
      "Epoch 977/1000\n",
      "474/474 [==============================] - 0s 98us/step - loss: 0.5782 - acc: 0.6941 - val_loss: 2.0927 - val_acc: 0.5472\n",
      "Epoch 978/1000\n",
      "474/474 [==============================] - 0s 96us/step - loss: 0.5777 - acc: 0.6857 - val_loss: 2.0991 - val_acc: 0.5031\n",
      "Epoch 979/1000\n",
      "474/474 [==============================] - 0s 96us/step - loss: 0.5887 - acc: 0.6709 - val_loss: 2.1090 - val_acc: 0.5597\n",
      "Epoch 980/1000\n",
      "474/474 [==============================] - 0s 96us/step - loss: 0.5845 - acc: 0.6772 - val_loss: 2.1000 - val_acc: 0.5283\n",
      "Epoch 981/1000\n",
      "474/474 [==============================] - 0s 101us/step - loss: 0.5879 - acc: 0.6751 - val_loss: 2.1117 - val_acc: 0.5283\n",
      "Epoch 982/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.5757 - acc: 0.6814 - val_loss: 2.0910 - val_acc: 0.5912\n",
      "Epoch 983/1000\n",
      "474/474 [==============================] - 0s 98us/step - loss: 0.5924 - acc: 0.6709 - val_loss: 2.1703 - val_acc: 0.4906\n",
      "Epoch 984/1000\n",
      "474/474 [==============================] - 0s 99us/step - loss: 0.6483 - acc: 0.6688 - val_loss: 2.1111 - val_acc: 0.5597\n",
      "Epoch 985/1000\n",
      "474/474 [==============================] - 0s 100us/step - loss: 0.6575 - acc: 0.6435 - val_loss: 2.1085 - val_acc: 0.5346\n",
      "Epoch 986/1000\n",
      "474/474 [==============================] - 0s 105us/step - loss: 0.6023 - acc: 0.6772 - val_loss: 2.1264 - val_acc: 0.5094\n",
      "Epoch 987/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.5936 - acc: 0.6814 - val_loss: 2.0878 - val_acc: 0.4843\n",
      "Epoch 988/1000\n",
      "474/474 [==============================] - 0s 111us/step - loss: 0.5935 - acc: 0.6667 - val_loss: 2.1151 - val_acc: 0.5031\n",
      "Epoch 989/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.5756 - acc: 0.6709 - val_loss: 2.1378 - val_acc: 0.5660\n",
      "Epoch 990/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.5806 - acc: 0.6751 - val_loss: 2.0968 - val_acc: 0.5409\n",
      "Epoch 991/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.5918 - acc: 0.6814 - val_loss: 2.1033 - val_acc: 0.5220\n",
      "Epoch 992/1000\n",
      "474/474 [==============================] - 0s 108us/step - loss: 0.5729 - acc: 0.7194 - val_loss: 2.1417 - val_acc: 0.4717\n",
      "Epoch 993/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.5968 - acc: 0.6624 - val_loss: 2.1459 - val_acc: 0.4717\n",
      "Epoch 994/1000\n",
      "474/474 [==============================] - 0s 109us/step - loss: 0.6034 - acc: 0.6709 - val_loss: 2.1216 - val_acc: 0.5723\n",
      "Epoch 995/1000\n",
      "474/474 [==============================] - 0s 107us/step - loss: 0.5939 - acc: 0.6603 - val_loss: 2.0438 - val_acc: 0.5157\n",
      "Epoch 996/1000\n",
      "474/474 [==============================] - 0s 104us/step - loss: 0.6401 - acc: 0.6941 - val_loss: 2.0814 - val_acc: 0.5660\n",
      "Epoch 997/1000\n",
      "474/474 [==============================] - 0s 103us/step - loss: 0.6032 - acc: 0.6751 - val_loss: 2.1007 - val_acc: 0.5157\n",
      "Epoch 998/1000\n",
      "474/474 [==============================] - 0s 112us/step - loss: 0.5823 - acc: 0.6772 - val_loss: 2.0916 - val_acc: 0.5660\n",
      "Epoch 999/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.5803 - acc: 0.6688 - val_loss: 2.1460 - val_acc: 0.5597\n",
      "Epoch 1000/1000\n",
      "474/474 [==============================] - 0s 106us/step - loss: 0.5858 - acc: 0.6814 - val_loss: 2.1268 - val_acc: 0.5157\n"
     ]
    }
   ],
   "source": [
    "# Let us train the model\n",
    "history = model.fit(features_train, labels_train, epochs=1000, validation_data=(features_test, labels_test), batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 49us/step\n",
      "Loss:  2.1267692293\n",
      "Accuracy on the test set:  0.515723267066\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(features_test)\n",
    "e = model.evaluate(features_test, labels_test)\n",
    "print (\"Loss: \", e[0])\n",
    "print (\"Accuracy on the test set: \", e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.88489327e-12,   3.14878129e-18,   2.58467764e-26, ...,\n",
       "          1.78388362e-08,   2.34954502e-03,   1.41198167e-26],\n",
       "       [  3.77800546e-08,   4.37068408e-08,   1.09651204e-07, ...,\n",
       "          1.74638992e-21,   1.98601648e-17,   0.00000000e+00],\n",
       "       [  2.73054183e-11,   2.45438420e-10,   8.80327922e-10, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  1.52845114e-08,   3.42711743e-08,   4.38011397e-04, ...,\n",
       "          1.02629394e-09,   7.27901443e-06,   1.32194672e-31],\n",
       "       [  3.68139154e-04,   5.05491674e-01,   3.75506011e-06, ...,\n",
       "          1.99810401e-33,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.26554328e-03,   1.78656580e-06,   0.00000000e+00, ...,\n",
       "          6.77440169e-31,   3.77130776e-34,   4.37663541e-24]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we we will use np.argmax to get the max probability and the index\n",
    "pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8,  4,  6,  8,  1,  8,  5,  9,  7,  8,  0,  3,  7,  0,  7,  2,\n",
       "        1, 10,  1,  1, 10,  1,  3,  8,  4, 10, 10,  4, 11,  0,  1, 10,  4,\n",
       "        6, 11,  4,  4,  4,  8,  1,  4,  8,  5,  4,  6, 10,  4,  8, 10,  8,\n",
       "        7,  5,  6,  2, 12, 10,  1,  5,  5,  0,  1,  4,  4,  7,  9,  0,  0,\n",
       "        0,  1,  9,  4,  8,  6,  8,  1,  5,  8,  6, 10, 10,  8,  4,  8,  4,\n",
       "        5,  4,  8,  5,  6,  1, 12,  4,  5, 10,  4,  8,  9,  1, 11,  0, 12,\n",
       "        1,  9, 12,  1,  4,  8,  1,  7, 10,  9,  6,  8,  8,  4, 12,  1,  4,\n",
       "        8,  6,  5,  4,  8,  9,  0,  8,  1,  9,  9,  0,  5,  1, 10,  1,  9,\n",
       "        6,  8,  1,  1,  8,  7,  4,  0,  8,  0,  1,  1,  0,  4,  6,  5,  4,\n",
       "        4,  4,  4,  4,  1,  9])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_labels_test = np.argmax(labels_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8,  4,  6,  4,  8,  5,  9,  7,  7,  8,  0,  3,  8,  4,  7,  5,\n",
       "        1,  8,  7,  1, 10,  7,  4,  5,  4, 10,  6,  4,  8,  7,  7, 10,  4,\n",
       "        9,  5,  8,  4,  4, 12,  1,  3,  8,  0,  4,  5, 10,  4,  6,  4,  8,\n",
       "        7,  5,  6,  7,  2,  6,  1,  5,  5,  0,  1,  6,  7,  7,  8,  5,  0,\n",
       "        0,  5,  9,  3,  9,  7,  4,  7,  5,  8,  6,  1,  5,  8,  4,  8, 10,\n",
       "        5,  2,  8,  5,  8,  1,  1,  2,  5,  1,  4,  8,  9,  1, 11,  8,  6,\n",
       "        1,  1, 12,  1,  1,  9,  1,  8,  5,  1,  7,  8,  7,  4,  5,  8,  7,\n",
       "       10,  5,  5,  8,  8,  9,  0,  9,  1,  9,  9,  7,  9,  1,  9,  5,  9,\n",
       "        6,  8,  9,  1,  8, 10,  9,  3,  8,  0,  8,  1,  5,  4,  1,  5,  4,\n",
       "        7,  4,  4,  4,  1,  0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the mode is :  0.51572327044\n"
     ]
    }
   ],
   "source": [
    "# Checking accuracy (Using a 3 hidden layer neural network)\n",
    "print (\"The accuracy of the mode is : \", accuracy_score(decoded_labels_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50314465408805031"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(features_copy_train, labels_copy_train)\n",
    "clf.score(features_copy_test, labels_copy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  6,  6,  8,  4,  1,  8,  6,  5,  1,  8,  1,  8,  0,  5, 10,  8,\n",
       "        6,  2, 10,  4,  2,  1, 10,  8,  6,  6,  9,  7,  7, 10,  1,  1,  6,\n",
       "        9,  6,  1,  1,  8,  1,  0, 13,  9,  7,  4,  6,  1,  2,  9,  9,  1,\n",
       "        1,  4,  4,  0,  7,  7,  9, 13,  7,  1,  9,  1,  6,  6, 12,  5,  4,\n",
       "        0,  0,  7,  0,  1,  6,  4,  5,  0,  9,  2,  9,  1,  0,  7,  9, 12,\n",
       "        8,  8,  7,  9,  9,  0,  9,  4,  0,  9,  7,  6,  6,  8,  5, 10,  7,\n",
       "        0,  2,  7,  1,  7,  1,  4,  4,  7,  1,  7,  8,  4,  1,  4,  5,  1,\n",
       "        1, 10,  7,  9,  8,  4, 10,  1,  1,  4,  5,  5, 12,  7,  6, 13,  1,\n",
       "        9,  4,  4,  5,  4,  8,  7,  2,  4,  0,  2,  5,  0,  5,  3,  6,  4,\n",
       "        1,  7,  7,  4,  6,  4,  8,  8, 10,  1,  5,  1,  8,  6,  5,  3,  6,\n",
       "        1,  0,  1,  5,  8,  9,  1,  9,  2,  4,  9,  7,  8,  8, 10,  9,  1,\n",
       "       13,  1,  1,  9,  5,  0,  8,  6,  0,  1,  6,  0,  6,  9,  7, 13,  7,\n",
       "        1,  7,  4,  5,  6,  8,  1,  9,  1,  1,  1,  5,  5,  5,  5,  4,  9,\n",
       "        4,  6,  5,  7,  9,  6,  8,  5,  6,  0,  6,  1,  5,  9, 10,  5,  4,\n",
       "        9,  8,  7,  6,  4, 10,  9,  7,  8,  5,  8,  6,  6, 10,  9,  4, 11,\n",
       "       11,  0,  5,  4,  6,  7, 11,  1,  9,  5,  0,  7,  1,  4,  9,  8,  4,\n",
       "        8,  6,  5,  3, 10,  7,  1,  1,  1,  2,  5,  8,  9,  8,  0,  0, 10,\n",
       "        4,  0,  7,  8,  9,  6,  5,  5,  0,  5,  1,  8, 10,  8,  1,  9,  6,\n",
       "        1,  8,  7,  5,  9,  4,  6,  4,  8,  8, 10,  0,  4,  5,  1, 10,  0,\n",
       "        5,  8,  6, 10,  4,  1, 12,  6,  1,  7,  5,  7,  4,  9,  6,  5,  6,\n",
       "        6, 12,  1,  7,  9,  9,  9,  2,  0,  5,  4,  4,  4,  0,  9,  1,  1,\n",
       "        9,  4,  1,  1,  0, 12,  8,  7,  4,  5,  1,  6,  5,  7,  3,  1,  7,\n",
       "        3,  8,  1,  5,  8,  8,  9, 12,  5,  4,  4,  6,  6,  7,  4,  9,  6,\n",
       "        1,  6,  8,  5,  4,  4,  1,  6,  7, 11,  6,  1,  0,  5,  8,  8,  0,\n",
       "        9,  8,  7,  4,  8,  3,  6,  0,  7,  8,  7,  8,  7,  1,  8,  5, 10,\n",
       "        1,  5,  1,  5,  5,  9, 11,  4,  5,  7,  5,  5, 12,  8,  6,  7,  0,\n",
       "        7,  1,  9,  8, 10,  1, 12,  9,  7,  1,  4,  7,  5,  1,  6, 12, 10,\n",
       "        7,  6,  5,  7,  8,  7,  5,  8,  6,  0, 10,  4,  9,  5,  8])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_copy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43396226415094341"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators=100)\n",
    "clf2.fit(features_copy_train, labels_copy_train)\n",
    "clf2.score(features_copy_test, labels_copy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On average, we are getting an accuracy of 50-ish %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving keras model\n",
    "model.save(\"match-predictor.h5\")\n",
    "plot_model(model, to_file=\"predictor-arch.png\",show_layer_names=False, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474, 3)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_model(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d68df26ff3b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Match against  Pune and Sunrisers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x.predict(np.array([ [3,0, 1]])) # Match against  Pune and Sunrisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pca = PCA()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(StandardScaler().fit_transform(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12162f940>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VPW9//HXh7DvSybsOyQIKltYFIWgtaKt4rVXSxAVQeii3lpv/VXr7eZtH3a717ZXb1s2FRfQeq2lV71WK2BdEgjIDoGwCEEgCSRhDVnm+/tjBjpNgQwwM2eW9/PxyIOZc74z583JyZsv50xmzDmHiIgkl0ZeBxARkchTuYuIJCGVu4hIElK5i4gkIZW7iEgSUrmLiCQhlbuISBJSuYuIJCGVu4hIEmrs1YbT09Ndnz59vNq8iEhCWrVqVZlzztfQOM/KvU+fPhQUFHi1eRGRhGRmn4YzTqdlRESSkMpdRCQJqdxFRJKQyl1EJAmp3EVEklCD5W5mC8ysxMw2nGW9mdmvzazIzNaZ2YjIxxQRkfMRzsz9WWDSOdbfAAwMfs0GfnPxsURE5GI0WO7OufeBQ+cYMhlY6ALygPZm1jVSAUVEkoHf71i7p4JfvbuNTZ8djvr2IvFLTN2BPSH3i4PL9tUfaGazCczu6dWrVwQ2LSISv8qPVfP+tlKWF5ayfGspB49VYwYdWzdlcLe2Ud12TH9D1Tk3B5gDkJ2drU/mFpGk4vc7Nn52mGWFJSwtLGHNngr8Djq0bMKETB85WRmMz/TRsVXTqGeJRLnvBXqG3O8RXCYikvQqj9fw/rZSlgVn52VHTwIwtEc77r9mIBOzfFzeoz1pjSymuSJR7kuA+81sMTAGqHTO/cMpGRGRZOBcYHa+fGspS7eUsHp3OX4H7Vs2YfxAHzlZPsZn+khv3czTnA2Wu5ktAnKAdDMrBr4PNAFwzv0WeBO4ESgCjgP3RCusiIgXKk/U8MG2MpYVlrBsaymlRwKz88u6t+O+iQPIycpgWM/Yz87PpcFyd87lNrDeAfdFLJGIiMecc2zed4RlW0tYtqWUVbvLqfM72jZvzNWZPiZmZTA+M52MNs29jnpWnr3lr4hIPDlcVcOH28pOnzvff7gKgCHd2vLVCf2YGJydN05LjF/sV7mLSEpyzlF44AjLCgPnzld9Wk6t39GmeWOuHphOTlYGOZk+MtrG7+z8XFTuIpIyjp6s5cOi4LnzwlL2VQZm55d0bcus8YHZ+fBe7WmSILPzc1G5i0jScs6xreTo6TJfuesQNXWO1s0ac9WAdB78nI8JmRl0aZeYs/NzUbmLSFI5drKWj7YfZGlhCcsLS9lbcQKAQV3aMOOqvkzMymBk7w5JMTs/F5W7iCQ05xzbS4+dnp2v2HmI6jo/rZqmMW5AOvdfM4AJmT66tW/hddSYUrmLSMI5Xl3Lx9sPBi6GFpZQXB6YnQ/MaM30cX3IyfSR3acjTRsn9+z8XFTuIhL3nHPsLDvG0sJSlhWWkL/zENW1flo2TePK/ul8Lac/EzJ99OjQ0uuocUPlLiJx6UR1HXk7DgbfhKuU3YeOA9Df14q7xvYmJyuDUX070KxxmsdJ45PKXUTixq6yYywNnjvP23GQk7V+mjdpxLj+6cy6ui85WRn07KjZeThU7iLimaqaU7PzwOmWXQcDs/N+6a24Y0xvcrJ8jO7bkeZNNDs/Xyp3EYmp3QePB2fnJXy84yBVNX6aNW7Elf07cc+4vuRk+ejdqZXXMROeyl1Eoqqqpo4VOw+dnp3vKDsGQJ9OLZkyqhc5WT7G9uuk2XmEqdxFJOL2HDrOsq2lLNtSwkfbD3Kipo6mjRtxRb9O3HlF4GJo33TNzqNJ5S4iF+1kbR0rd5af/ni57aWB2Xmvji25LbsHE7MyGNuvEy2aanYeKyp3EbkgeytOBMp8SykfbS/jeHUdTdMaMaZfR6YGL4b2S2+FWfx8gEUqUbmLSFiqa/0U7DoUON1SWMLWA0cB6NGhBbeO6M7ErAyu6N+Jlk1VK/FA3wUROat9lSdOv9/5h0VlHKuuo0maMaZvJ27P7klOlo/+vtaancchlbuInFZT52fVp+Wn31Fxy/4jAHRv34LJwwOz8yv7d6JVM1VHvNN3SCTFHThcdfodFT/YVsaRk7U0STOye3fkOzcOIicrg4EZmp0nGpW7SIqprfOzenfF6V/z37zvMABd2zXni0O7kpOVwbgB6bTW7Dyh6bsnkgJKDlexbGspywtLeX9bKUeqamncyBjZuwOP3DCInCwfWZ3baHaeRFTuIkmots7Pmj0Vp9/vfONngdl557bNuPHSruRk+Rg3MJ22zZt4nFSiReUukiRKj5xkefBlin/dVkbliRrSGhkje3Xg/03KIiczg0u6anaeKlTuIgmqzu9Ys6eC5cH3O1+/txIAX5tmfH5wZ3KyMrhqYDrtWmh2nopU7iIJ5ODRU7PzwLnziuM1NDIY0asD3/p8JjlZGQzu2pZGjTQ7T3Uqd5E4Vud3rCuuOP2Oiuv2VuIcpLduyrWDOpOT5ePqgem0b9nU66gSZ1TuInHm0LFq3g+eO1++tZTy4zWYwfCe7fnm5zKZmJXBkG6ancu5qdxFPOb3O9bvrTz9ypa1xRU4B51aNWViVgYTsnyMH+ijQyvNziV8KncRD5Qfq+b9bYHXnS/fWsrBY9WYwdAe7fnGtQOZmJXBZd3baXYuF0zlLhIDfr9j42eHT7/f+Zo9FfgddGjZhPGZPiZmZXD1wHQ6tW7mdVRJEip3kSipPF7DX4tKWbolMDsvO3oSgKE92nH/NQOZmOXj8h7tSdPsXKJA5S4SIc45Nu07fPqVLat3V1Dnd7RrcWp27mN8po90zc4lBlTuIhfhcFUNH2wrY+mWwCtbSo4EZueXdW/H13P6k5OVwbCemp1L7KncRc6Dc44t+4+cfkfFVZ+WU+d3tG3emKuD587HZ6aT0aa511ElxancRRpwpKqGD4vKgqdbStl/uAqAId3a8tUJ/ZgYnJ03TmvkcVKRvwmr3M1sEvArIA2Y55z7Sb31vYEFgA84BExzzhVHOKtITDjn2HrgaHB2XkLBrnJq/Y42zRtz9cB0crIyyMn0kdFWs3OJXw2Wu5mlAU8D1wHFwEozW+Kc2xQy7BfAQufcc2Z2DfAEcGc0AotEU8GuQzz48hqKy08AMKhLG2aN70dOpo8RvTvQRLNzSRDhzNxHA0XOuR0AZrYYmAyElvtg4KHg7aXA65EMKRILqz49xN0LVpDRtjk//dJlTMjMoEs7zc4lMYVT7t2BPSH3i4Ex9casBW4lcOrmn4A2ZtbJOXcwIilFomz17nLuXrCSjLbNWTx7LJ11ykUSXKT+j/ktYIKZfQJMAPYCdfUHmdlsMysws4LS0tIIbVrk4qzdU8Hd81fQqXVTFs1SsUtyCKfc9wI9Q+73CC47zTn3mXPuVufccOCx4LKK+k/knJvjnMt2zmX7fL6LiC0SGeuLK7lzfj4dWgWKXadhJFmEU+4rgYFm1tfMmgJTgCWhA8ws3cxOPdejBF45IxLXNuytZNr8fNq2aMKi2WPp1r6F15FEIqbBcnfO1QL3A28Dm4FXnHMbzexxM7s5OCwHKDSzrUBn4MdRyisSEZs+O8y0+fm0btaYRbPG0l3FLknGnHOebDg7O9sVFBR4sm1JbZv3HWbq3DxaNEnj5a9cQc+OLb2OJBI2M1vlnMtuaJxetCsppXD/Ee6Yl0/zJmksmj1WxS5JS+UuKWPbgSNMnZtHkzRj0ayx9O7UyutIIlGjcpeUUFRylNy5+aQ1ChR7n3QVuyQ3lbskve2lR8mdmwfAS7PG0s/X2uNEItGncpektrPsGLlz8nDOsXj2GAZkqNglNajcJWntChZ7nd/x0qyxDMho43UkkZjR+7lLUtp98Di5c/OorvPz0qwxZHZWsUtq0cxdks6eQ4FiP1FTxwszxzCoS1uvI4nEnMpdkkpx+XGmzMnj6MlaXrx3DIO7qdglNancJWnsrThB7tw8jlTV8OK9YxjSrZ3XkUQ8o3PukhT2VZ4gd04eFcdreGHmGC7trmKX1KaZuyS8/ZVV5M7Jo/xYNQtnjGZoz/ZeRxLxnMpdElrJ4Sqmzs2j9MhJnp0xmuG9OngdSSQu6LSMJKySI1VMmZvH/sNVLJwxmpG9Vewip2jmLgmp9MhJps7NZ39lFc/eM5rsPh29jiQSV1TuknDKjp7kjnl57C0/wYLpoxjdV8UuUp/KXRLKoWPVTJuXz+5Dx5k/PZux/Tp5HUkkLqncJWGUH6tm6tw8dpYdY/7do7iyf7rXkUTili6oSkKoOF7NHfPy2VF2jHl3ZTNugIpd5Fw0c5e4V3m8hmnz8ykqOcqcO0cyPtPndSSRuKdyl7hWeaKGuxbks3X/UX5350hysjK8jiSSEFTuEreOVNVw94IVbNp3mN9MG8HEQSp2kXCp3CUuHT1Zy90LVrBhbyVPTx3BtZd09jqSSEJRuUvcOXqylukLVrCuuJKnpo7g80O6eB1JJOHo1TISV46drGXGMyv5ZE8FT+UOZ9KlKnaRC6GZu8SN49W1zHh2Jat2l/OrKcO44bKuXkcSSVgqd4kLJ6rrmPlsASt3HeLJLw/ji5d38zqSSEJTuYvnqmrqmLWwgPydB/nP24dx81AVu8jF0jl38dSpYv9wexn/cdtQbhne3etIIklBM3fxTFVNHV95fhUfFJXxsy9dzq0jengdSSRpqNzFEydr6/jaC6tYvrWUn956Obdl9/Q6kkhSUblLzFXX+rnvxdUsLSzliVsv4/ZRKnaRSFO5S0xV1/q576XVvLu5hB/dcim5o3t5HUkkKancJWZq6vw8sGg172w6wOOThzBtbG+vI4kkLZW7xERNnZ9vLP6Etzce4Ps3DeauK/p4HUkkqancJepq6/w8+PIa3ly/n3/7wiXcM66v15FEkp7KXaKqts7PQ6+s5Y11+/jOjYO49+p+XkcSSQlhlbuZTTKzQjMrMrNHzrC+l5ktNbNPzGydmd0Y+aiSaOr8jm/9fi1L1n7GtycNYvb4/l5HEkkZDZa7maUBTwM3AIOBXDMbXG/YvwGvOOeGA1OA/450UEksdX7Hw6+u5fU1n/Hw9Vl8LUfFLhJL4czcRwNFzrkdzrlqYDEwud4YB7QN3m4HfBa5iJJo/H7Ht/9nHa+t3stD12Vy38QBXkcSSTnhlHt3YE/I/eLgslA/AKaZWTHwJvDAmZ7IzGabWYGZFZSWll5AXIl3fr/j0dfW8+qqYr5x7UD+5dqBXkcSSUmRuqCaCzzrnOsB3Ag8b2b/8NzOuTnOuWznXLbPp0+wTzZ+v+Ox1zfwcsEeHrhmAA9+TsUu4pVwyn0vEPr74T2Cy0LNBF4BcM59DDQH0iMRUBKDc47vLdnAohW7+XpOfx66LhMz8zqWSMoKp9xXAgPNrK+ZNSVwwXRJvTG7gWsBzOwSAuWu8y4pwjnH95ds5IW83XxlQj8evj5LxS7isQbL3TlXC9wPvA1sJvCqmI1m9riZ3Rwc9q/ALDNbCywCpjvnXLRCS/xwzvH4/25i4cefMuvqvjwyaZCKXSQOhPVhHc65NwlcKA1d9r2Q25uAcZGNJvHOOceP39jMMx/uYsa4vnznxktU7CJxQr+hKhfEOcdP3trCvA92Mv3KPnz3iyp2kXiicpfz5pzjZ28X8rv3d3DXFb35/k2DVewicUblLufFOcd//Hkrv1m2nTvG9OKHNw9RsYvEIZW7nJcn393GU0uLyB3dk3+ffKmKXSROqdwlbL96dxu//ss2vpzdkx/fchmNGqnYReKVyl3C8tR723jy3a3888gePHGril0k3qncpUH/vayIX/x5K7cO785Pv3S5il0kAajc5Zx+t3w7P/u/Qm4Z1o2f3zaUNBW7SEJQuctZzfvrDp54aws3De3GL1TsIglF5S5nNP+Dnfzojc184bKuPHn7UBqn6VARSST6iZV/8OyHO/n3/93EDZd24ZdThqnYRRKQfmrl7zz/8S5+8KdNfH5wZ36dO5wmKnaRhKSfXDntxfxP+e4fN/K5Szrz1NQRKnaRBKafXgFg0YrdPPaHDVwzKIOn7xhO08Y6NEQSmX6ChVdW7uHR19aTk+XjN9NG0KxxmteRROQiqdxT3Kurivn2a+sYn+njt9NGqthFkoTKPYW9trqYh19dy1UD0plz50iaN1GxiyQLlXuK+uOavXzr92u5ol8n5tyZrWIXSTIq9xS0ZO1nfPPlNYzu25H5d4+iRVMVu0iyUbmnmDfW7eObL68hu09HFkxXsYskK5V7Cnlr/T7+ZfEnjOjVnmemj6Jl07A+H11EEpDKPUX834b9PLDoE4b1bM8z94ymVTMVu0gyU7mngHc2HeD+l1ZzWY92PHvPKFqr2EWSnso9yb235QBff3EVQ7q347kZo2nTvInXkUQkBlTuSWxpYQlffX41l3Rty8IZo2mrYhdJGSr3JLV8aylfeX4VmV1a8/yMMbRroWIXSSUq9yT0wbYyZi8sYICvNS/MHEO7lip2kVSjck8yHxWVMfO5lfRNb8WL946hfcumXkcSEQ+o3JPIx9sPMuO5lfTpFCj2Dq1U7CKpSuWeJPJ3HGTGsyvp2aElL84aQ6fWzbyOJCIeUrkngZW7DnHPsyvp3qEFL80aS7qKXSTlqdwT3KpPDzF9wQq6tGvOS7PG4GujYhcRlXtCW727nLsXrCSjbXMWzRpLRpvmXkcSkTihck9Qa/ZUcPf8FXRq3ZRFs8bSua2KXUT+RuWegNYVV3Dn/Hw6tAoUe5d2KnYR+Xsq9wSzYW8l0+bl065FExbNHku39i28jiQicSiscjezSWZWaGZFZvbIGdY/aWZrgl9bzawi8lFl42eV3DEvnzbNm7Bo1li6q9hF5CwafO9XM0sDngauA4qBlWa2xDm36dQY59w3Q8Y/AAyPQtaUtnnfYabNy6dV0zQWzx5Lz44tvY4kInEsnJn7aKDIObfDOVcNLAYmn2N8LrAoEuEkoHD/Ee6Yl0/zJmksUrGLSBjCKffuwJ6Q+8XBZf/AzHoDfYH3Lj6aAGw9cISpc/NokmYsmjWW3p1aeR1JRBJApC+oTgFedc7VnWmlmc02swIzKygtLY3wppNPUUmg2NMaBYq9T7qKXUTCE0657wV6htzvEVx2JlM4xykZ59wc51y2cy7b5/OFnzIFbS89Su7cfMB4adZY+vlaex1JRBJIOOW+EhhoZn3NrCmBAl9Sf5CZDQI6AB9HNmLq2VF6lNw5eTjnWDx7DAMyVOwicn4aLHfnXC1wP/A2sBl4xTm30cweN7ObQ4ZOARY751x0oqaGXWXHyJ2bR53f8dKssQzIaON1JBFJQA2+FBLAOfcm8Ga9Zd+rd/8HkYuVmj49GCj2mjrHS7PGkNlZxS4iF0a/oRon9hw6Tu6cPE7U1PHCzDEM6tLW60giksBU7nGguPw4U+bkcay6jhfvHcPgbip2Ebk4KneP7a04Qe7cPI5U1fDivWMY0q2d15FEJAmEdc5domNf5Qly5+RRcTxQ7Jd2V7GLSGRo5u6R/ZVV5M7Jo/xYNc/PHMPlPdp7HUlEkohm7h4oOVzF1Ll5lB2tZuHM0QzrqWIXkcjSzD3GSo5UMWVuHgcOV/HcjFGM6NXB60gikoQ0c4+h0iMnmTo3n/2VVTw3YzQje3f0OpKIJCnN3GOk7OhJ7piXx97yEzwzfRSj+qjYRSR6VO4xcOhYNdPm5bP70HEWTB/FmH6dvI4kIklO5R5l5ceqmTo3j51lx5h/9yiu6K9iF5Ho0zn3KKo4Xs0d8/LZUXaMeXdlM25AuteRRCRFaOYeJZXHa5g2P5+ikqPMuXMk4zP1/vUiEjsq9yioPFHDnQvy2br/KL+7cyQ5WRleRxKRFKNyj7DDVTXctWAFm/cd5jfTRjBxkIpdRGJP5R5BR6pquHvBCjbureTpqSO49pLOXkcSkRSlco+Qoydrmf7MStYXV/LU1BF8fkgXryOJSArTq2Ui4NjJWu55ZgVr9lTwVO5wJl2qYhcRb2nmfpGOV9dyz7MrWb27gl9NGcYNl3X1OpKIiMr9YpyormPmswUU7DrEk18exhcv7+Z1JBERQOV+wapq6rh34Urydx7kP28fxs1DVewiEj90zv0CVNXUMWthAR9tP8h/3DaUW4Z39zqSiMjf0cz9PFXV1DH7+VV8UFTGz750ObeO6OF1JBGRf6ByPw8na+v42gureH9rKT+99XJuy+7pdSQRkTNSuYfpZG0dX39hNUsLS3ni1su4fZSKXUTil8o9DNW1fu5/6RP+sqWEH91yKbmje3kdSUTknFTuDaip8/PAotW8s+kAj08ewrSxvb2OJCLSIJX7OdTU+fnG4k94e+MBfnDTYO66oo/XkUREwqJyP4vaOj8PvryGN9fv57tfHMz0cX29jiQiEjaV+xnU1vl56JW1vLFuH4/deAkzr1Kxi0hiUbnXU+d3fOv3a1my9jMeuWEQs8b38zqSiMh5U7mHqPM7Hn51La+v+YyHr8/iqxP6ex1JROSCqNyD/H7Ht/9nHa+t3su/XpfJfRMHeB1JROSCqdwJFPujr63n1VXFfOPagTxw7UCvI4mIXJSUL3e/3/HY6xt4uWAPD1wzgAc/p2IXkcSX0uXunON7SzawaMVuvp7Tn4euy8TMvI4lInLRUrbcnXN8f8lGXsjbzVcm9OPh67NU7CKSNMIqdzObZGaFZlZkZo+cZcztZrbJzDaa2UuRjRlZzjl++KdNLPz4U2Zd3ZdHJg1SsYtIUmnwwzrMLA14GrgOKAZWmtkS59ymkDEDgUeBcc65cjPLiFbgi+Wc40dvbObZj3YxY1xfvnPjJSp2EUk64czcRwNFzrkdzrlqYDEwud6YWcDTzrlyAOdcSWRjRoZzjife2sL8D3Yy/co+fPeLKnYRSU7hlHt3YE/I/eLgslCZQKaZfWhmeWY26UxPZGazzazAzApKS0svLPEFcs7x0/8rZM77O7jrit58/6bBKnYRSVqRuqDaGBgI5AC5wFwza19/kHNujnMu2zmX7fP5IrTphjnn+MWfC/nt8u3cMaYXP7x5iIpdRJJaOOW+Fwj92KEewWWhioElzrka59xOYCuBso8LT76zlaeXbid3dE/+ffKlKnYRSXrhlPtKYKCZ9TWzpsAUYEm9Ma8TmLVjZukETtPsiGDOC/bLd7fy6/eK+HJ2T358y2U0aqRiF5Hk12C5O+dqgfuBt4HNwCvOuY1m9riZ3Rwc9jZw0Mw2AUuBh51zB6MVOlz/9Zdt/PLdbfzzyB48cauKXURShznnPNlwdna2KygoiNrzP720iJ+/Xcitw7vz89uGkqZiF5EkYGarnHPZDY1Lyt9Q/e3y7fz87UJuGdZNxS4iKSnpyn3u+zv4yVtbuGloN36hYheRFJVU5T7vrzv48Zub+cLlXXny9qE0Tkuqv56ISNiSpv2e+XAnP3pjMzdc2oVffnmYil1EUlpSNODCj3fxwz9t4vohnfl17nCaqNhFJMUlfAu+mP8p3/vjRq4b3Jn/yh2hYhcRIcHLfdGK3Tz2hw1cOyiDp6eOoGnjhP7riIhETMK24Ssr9/Doa+uZmOXjv6ep2EVEQiVkI766qphvv7aOCZk+fjNtJM0ap3kdSUQkriRcub/+yV4efnUtVw1I53d3jqR5ExW7iEh9CVfu3Tu04LpLOjPnzmwVu4jIWTT4MXvxZlSfjozq09HrGCIicS3hZu4iItIwlbuISBJSuYuIJCGVu4hIElK5i4gkIZW7iEgSUrmLiCQhlbuISBLy7AOyzawU+PQCH54OlEUwTqQo1/lRrvMXr9mU6/xcTK7ezjlfQ4M8K/eLYWYF4Xz6d6wp1/lRrvMXr9mU6/zEIpdOy4iIJCGVu4hIEkrUcp/jdYCzUK7zo1znL16zKdf5iXquhDznLiIi55aoM3cRETmHuCt3M5tkZoVmVmRmj5xhfTMzezm4Pt/M+oSsezS4vNDMro9xrofMbJOZrTOzv5hZ75B1dWa2Jvi1JMa5pptZacj27w1Zd7eZbQt+3R3jXE+GZNpqZhUh66K5vxaYWYmZbTjLejOzXwdzrzOzESHrorK/wsh0RzDLejP7yMyGhqzbFVy+xswKIpXpPLLlmFllyPfreyHrznkMRDnXwyGZNgSPqY7BdVHZZ2bW08yWBntgo5l94wxjYnd8Oefi5gtIA7YD/YCmwFpgcL0xXwd+G7w9BXg5eHtwcHwzoG/wedJimGsi0DJ4+2uncgXvH/Vwf00HnjrDYzsCO4J/dgje7hCrXPXGPwAsiPb+Cj73eGAEsOEs628E3gIMGAvkx2B/NZTpylPbAm44lSl4fxeQ7uH+ygH+92KPgUjnqjf2JuC9aO8zoCswIni7DbD1DD+PMTu+4m3mPhoocs7tcM5VA4uByfXGTAaeC95+FbjWzCy4fLFz7qRzbidQFHy+mORyzi11zh0P3s0DekRo2xeV6xyuB95xzh1yzpUD7wCTPMqVCyyK0LbPyTn3PnDoHEMmAwtdQB7Q3sy6EsX91VAm59xHwW1C7I6tU9tuaH+dzcUcm5HOFZPjyzm3zzm3Onj7CLAZ6F5vWMyOr3gr9+7AnpD7xfzjzjk9xjlXC1QCncJ8bDRzhZpJ4F/nU5qbWYGZ5ZnZLRHKdD65vhT8L+CrZtbzPB8bzVwET1/1Bd4LWRyt/RWOs2WP5v46H/WPLQf82cxWmdlsD/IAXGFma83sLTMbElwWF/vLzFoSKMn/CVkc9X1mgdPFw4H8eqtidnwl3GeoxjszmwZkAxNCFvd2zu01s37Ae2a23jm3PUaR/gQscs6dNLOvEPhfzzUx2nY4pgCvOufqQpZ5ub/ilplNJFDuV4Usviq4rzKAd8xsS3BWGyurCXy/jprZjcDrwMAYbr8hNwEfOudCZ/lR3Wdm1prAPyYPOucOR+p5z1e8zdz3Aj1D7vcILjvjGDNrDLQDDob52Gjmwsw+BzwG3OycO3lquXNub/DPHcAyAv+ixySXc+5gSJZ5wMhwHxvNXCGmUO+/zFHcX+E4W/Zo7q8GmdnlBL5/k51zB08tD9lXJcAfiNypyLA45w47544Gb78JNDFuNNQ9AAABuElEQVSzdDzeXyHOdXxFfJ+ZWRMCxf6ic+61MwyJ3fEV6YsKF3lBojGBCwl9+dtFmCH1xtzH319QfSV4ewh/f0F1B5G7oBpOruEELiANrLe8A9AseDsd2EaELiyFmatryO1/AvLc3y7g7Azm6xC83TFWuYLjBhG4uGWx2F8h2+jD2S8QfoG/v+C1Itr7K4xMvQhcQ7qy3vJWQJuQ2x8BkyK5r8LI1uXU949ASe4O7ruwjoFo5Qqub0fgvHyrWOyz4N97IfDLc4yJ2fEV0YMgQjvoRgJXmbcDjwWXPU5gNgzQHPh98GBfAfQLeexjwccVAjfEONe7wAFgTfBrSXD5lcD64MG9HpgZ41xPABuD218KDAp57IzgfiwC7ollruD9HwA/qfe4aO+vRcA+oIbAec2ZwFeBrwbXG/B0MPd6IDva+yuMTPOA8pBjqyC4vF9wP60Nfo8fi+S+CjPb/SHHVx4h/wCd6RiIVa7gmOkEXmQR+rio7TMCp8scsC7ke3WjV8eXfkNVRCQJxds5dxERiQCVu4hIElK5i4gkIZW7iEgSUrmLiCQhlbuISBJSuYuIJCGVu4hIEvr/cZHAjkH0q6AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
